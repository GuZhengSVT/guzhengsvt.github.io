<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Mathematics on 孤筝の温暖小家</title><link>https://guzhengsvt.cn/en/tags/mathematics/</link><description>Recent content from 孤筝の温暖小家</description><generator>Hugo</generator><language>en</language><managingEditor>lvbowen040427@163.com (孤筝)</managingEditor><webMaster>lvbowen040427@163.com (孤筝)</webMaster><copyright>Unless otherwise stated, all posts on this blog are licensed under the BY-NC-SA license. Please credit the source when reposting!</copyright><lastBuildDate>Tue, 10 Sep 2024 01:14:05 +0800</lastBuildDate><atom:link href="https://guzhengsvt.cn/en/tags/mathematics/index.xml" rel="self" type="application/rss+xml"/><item><title>Probability Theory and Mathematical Statistics</title><link>https://guzhengsvt.cn/en/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/</link><pubDate>Tue, 10 Sep 2024 01:14:05 +0800</pubDate><author>lvbowen040427@163.com (孤筝)</author><guid>https://guzhengsvt.cn/en/post/math/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/</guid><description>
<![CDATA[<h1>Probability Theory and Mathematical Statistics</h1><p>Author: 孤筝 (lvbowen040427@163.com)</p>
        
          <h2 id="preface">
<a class="header-anchor" href="#preface"></a>
Preface
</h2><h3 id="first-edition-preface">
<a class="header-anchor" href="#first-edition-preface"></a>
First Edition Preface
</h3><p>[[2024-09-14]] Today the makeup exam finally ended. I heard the original exam directly reused past papers. These past few days I practiced three sets of &ldquo;XDU original papers&rdquo; (from 2021 and two from 2023) found online. I did the 2021 paper in the morning, and in the afternoon $\frac{1}{4}$ of the questions were exact copies without any changes. I couldn&rsquo;t help but laugh.</p>
<p>Dai Hao once said he would try his best to find the best teachers for the Qian Class. But now it seems the School of Mathematics and Statistics has no one left? Poor teaching could be excused as not focusing on education or lacking talent in teaching; but directly reusing recent past papers for exams, full of unchecked errors and omissions, made me laugh in frustration.</p>
<p>The exams they create have no value, and they don&rsquo;t even bother to test them themselves. This is an attitude problem.</p>
<p>It&rsquo;s fine that your university goes easy on final exams, but don&rsquo;t keep fooling people with old material. You preach innovation to students, yet for yourselves, just getting by is enough. This is not the attitude for academic work, nor is it the attitude one should have for teaching.</p>
<p>Probability theory ends here for now. Over the past two days, I repeatedly reviewed notes, practiced problems, and corrected many errors, clarifying the knowledge structure of this course. Although the content is still relatively sparse, it should suffice as final review material. This edition will likely be the final version (probably).
I&rsquo;ll continue organizing Electrodynamics and Digital Signal Processing during the Mid-Autumn Festival.</p>
<h3 id="second-edition-preface">
<a class="header-anchor" href="#second-edition-preface"></a>
Second Edition Preface
</h3><blockquote>
<p>Nothing is final!!!
——Qian Xuesen</p></blockquote>
<p>Added content on the left/right continuity of distribution functions. It seems this course is far from final&hellip;</p>
<h2 id="event-operations-to-logical-operations">
<a class="header-anchor" href="#event-operations-to-logical-operations"></a>
Event Operations to Logical Operations
</h2><ul>
<li>$A \cup B=A+B$</li>
<li>$A \cap B=A \cdot B$</li>
<li>$A-B=A \bar{B}$
Event $A$ occurs and event $B$ does not occur, easily proven by Venn diagrams.
$-B$ can be interpreted as $\cdot (-B)$, where $-B$ is $\bar{B}$.</li>
<li>If $A \subset B$, then $A \cup B=B$, $A \cap B=A$.</li>
</ul>
<p>After converting event operations to logical operations, most rules are shared.
Using logical function operations and simplification learned in digital circuits, complex event operations can be simplified.
Tips: Karnaugh maps.</p>
<h2 id="four-major-probability-formulas">
<a class="header-anchor" href="#four-major-probability-formulas"></a>
Four Major Probability Formulas
</h2>$$
\begin{cases}
P(A+B)=P(A)+P(B)-P(AB)\\
P(A-B)=P(A)-P(AB)=P(A \bar{B})\\
P(AB)=P(B) \cdot P(A|B)=P(A) \cdot P(B|A)\\
P(A|B)=\frac{P(AB)}{P(B)}\\
\end{cases}
$$<h3 id="corollary">
<a class="header-anchor" href="#corollary"></a>
Corollary
</h3><p>$P(A+B+C)$: Treat $A+B$ as a single event and apply the addition formula above, splitting twice to get:
</p>
$$
P(A+B+C)=P(A)+P(B)+P(C)-P(AB)-P(AC)-P(BC)+P(ABC)
$$<p>
Probabilities for more joint events can be derived recursively.</p>
<p>Complementary event: The probability that $A$ does not occur, obvious from Venn diagrams.
</p>
$$
P(\bar{A})=P(1 \cdot \bar{A})=P(1-A)=P(1)-P(1 \cdot A)=1-P(A)
$$<h2 id="non-negativity-and-normalization">
<a class="header-anchor" href="#non-negativity-and-normalization"></a>
Non-Negativity and Normalization
</h2><p>Non-negativity: For any event $A$, $0 \le P(A) \le 1$.
Normalization: For the total event $\Omega$, $P(\Omega)=1$.</p>
<h2 id="independence">
<a class="header-anchor" href="#independence"></a>
Independence
</h2>$$
\begin{cases}
P(AB)=P(A) \cdot P(B)\\
P(A|B)=P(A)
\end{cases}
$$<p>
Independence implies mutual independence.</p>
<h2 id="classical-probability-model">
<a class="header-anchor" href="#classical-probability-model"></a>
Classical Probability Model
</h2><blockquote>
<p>All elementary events have equal probability.</p></blockquote>
<p>Eg. Coin toss, dice roll&hellip;
</p>
$$
P(A)=\frac{\text{Number of elementary events in } A}{\text{Total elementary events in } \Omega}
$$<p>
Classical conditional probability formula:
</p>
$$
P(B|A)=\frac{P(AB)}{P(A)}=\frac{\text{Elementary events in both } A \text{ and } B}{\text{Elementary events in } A}
$$<h2 id="bernoulli-trials-binomial-distribution">
<a class="header-anchor" href="#bernoulli-trials-binomial-distribution"></a>
Bernoulli Trials (Binomial Distribution)
</h2><blockquote>
<p>$n$ independent trials, each with only two outcomes: $A$ or $\bar{A}$.</p></blockquote>
<p>$X \sim B(n,p)$
</p>
$$
P_n(k)=C_n^kp^k(1-p)^{n-k}
$$<p>
Where $p=P(A)$, $1-p=P(\bar{A})$.</p>
<h2 id="geometric-probability-model">
<a class="header-anchor" href="#geometric-probability-model"></a>
Geometric Probability Model
</h2><p>The ratio of the <em>length/area/volume</em> occupied by the event to the total <em>length/area/volume</em> of the sample space $\Omega$.
When the event&rsquo;s dimension is lower than $\Omega$&rsquo;s dimension, its probability is always 0.
==Warning==: A probability of 0 does not mean the event cannot occur.
Eg: Randomly selecting a point inside a circle, the probability of selecting any specific point is 0, but it can still happen.</p>
<h2 id="uniform-distribution">
<a class="header-anchor" href="#uniform-distribution"></a>
Uniform Distribution
</h2><p>$x \sim U(a,b)$
Approximates a linear distribution in geometric probability, with probability density:
</p>
$$
f(x)=
\begin{cases}
0,x \le a\\
\frac{1}{b-a},a  \lt  x \le b\\
0,x \gt b\\
\end{cases}
$$<p>Cumulative distribution function:
</p>
$$
F(x)=
\begin{cases}
0,x \le a\\
\frac{x-a}{b-a},a \lt x \le b\\
1,x \gt b\\
\end{cases}
$$<h2 id="exponential-distribution">
<a class="header-anchor" href="#exponential-distribution"></a>
Exponential Distribution
</h2><p>$x \sim E(\lambda)$</p>
<h3 id="probability-density">
<a class="header-anchor" href="#probability-density"></a>
Probability Density
</h3>$$
f(x)=
\begin{cases}
\lambda e^{-\lambda x},x \gt 0\\
0,x \le 0\\
\end{cases}
$$<h3 id="cumulative-distribution-function">
<a class="header-anchor" href="#cumulative-distribution-function"></a>
Cumulative Distribution Function
</h3>$$
F(x)=
\begin{cases}
1-e^{-\lambda x},x \ge 0\\
0,x \lt 0\\
\end{cases}
$$<h2 id="poisson-distribution">
<a class="header-anchor" href="#poisson-distribution"></a>
Poisson Distribution
</h2><p>$X \sim \pi(\lambda)$
</p>
$$
P(X=k)=\frac{e^{-\lambda}\lambda^k}{k!}
$$<h2 id="normal-distribution">
<a class="header-anchor" href="#normal-distribution"></a>
Normal Distribution
</h2><p>$x \sim N(\mu,\sigma^2)$</p>
<h3 id="probability-density-1">
<a class="header-anchor" href="#probability-density-1"></a>
Probability Density
</h3>$$
f(x)=\frac{1}{\sqrt{2 \pi} \sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}},x \in R,\sigma \gt 0
$$<h3 id="cumulative-distribution-function-1">
<a class="header-anchor" href="#cumulative-distribution-function-1"></a>
Cumulative Distribution Function
</h3>$$
F(x)=\int^{x}_{-\infty}f(t)dt
$$<p>
Clearly, $F(\mu)=\frac{1}{2}$, meaning $P(x \le \mu)=P(x \gt \mu)=\frac{1}{2}$.</p>
<h3 id="standard-normal-distribution">
<a class="header-anchor" href="#standard-normal-distribution"></a>
Standard Normal Distribution
</h3><p>When $\mu=0,\sigma=1$, it becomes the standard normal distribution.
</p>
$$
\varphi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}
$$<p>
</p>
$$
\varPhi(x)=\int^{x}_{-\infty}\varphi(t)dt
$$<h3 id="corollaries">
<a class="header-anchor" href="#corollaries"></a>
Corollaries
</h3>$$
\varPhi(-x)=1-\varPhi(x)
$$<p>
</p>
$$
F(x)=\varPhi(\frac{x-\mu}{\sigma})
$$<p>
Normalization of normal distribution:
</p>
$$
X \sim N(\mu,\sigma^2),Z=\frac{X-\mu}{\sigma}\sim N(0,1)
$$<h2 id="total-probability-formula">
<a class="header-anchor" href="#total-probability-formula"></a>
Total Probability Formula
</h2><h3 id="complete-event-group">
<a class="header-anchor" href="#complete-event-group"></a>
Complete Event Group
</h3>$$
\begin{cases}
B_1 \cup B_2 \cup B_3 \cup \cdots \cup B_n=\Omega\\
B_i \cap B_j=\varnothing,i \ne j,1 \le i \le n,1 \le j \le n\\
\end{cases}
$$<p>
$B_1,B_2,B_3,\cdots B_n$ form a complete event group for $\Omega$.</p>
<h3 id="total-probability-formula-1">
<a class="header-anchor" href="#total-probability-formula-1"></a>
Total Probability Formula
</h3>$$
\begin{align}
P(A)
&=P(AB_1 \cup AB_2 \cup \cdots \cup AB_n)\\
&=P(AB_1)+P(AB_2)+\cdots +P(AB_n)\\
&=P(B_1)P(A|B_1)+P(B_2)P(A|B_2)+\cdots +P(B_n)P(A|B_n)\\
\end{align}
$$<h3 id="bayes-formula">
<a class="header-anchor" href="#bayes-formula"></a>
Bayes&rsquo; Formula
</h3>$$
P(B_1|A)=\frac{P(AB_1)}{P(A)}=\frac{P(B_1)P(A|B_1)}{P(A)}
$$<h2 id="one-dimensional-discrete-random-variables">
<a class="header-anchor" href="#one-dimensional-discrete-random-variables"></a>
One-Dimensional Discrete Random Variables
</h2><h3 id="probability-mass-function">
<a class="header-anchor" href="#probability-mass-function"></a>
Probability Mass Function
</h3>$$
P(X=x_i)=p_i=\frac{\text{Count of } X=x_i}{\text{Total count}},i=1,2,\cdots 
$$<h3 id="cumulative-distribution-function-2">
<a class="header-anchor" href="#cumulative-distribution-function-2"></a>
Cumulative Distribution Function
</h3>$$
F(x)=\sum_{x_i \lt x}p_i,x \in R
$$<h2 id="one-dimensional-continuous-random-variables">
<a class="header-anchor" href="#one-dimensional-continuous-random-variables"></a>
One-Dimensional Continuous Random Variables
</h2><h3 id="probability-density-function">
<a class="header-anchor" href="#probability-density-function"></a>
Probability Density Function
</h3>$$
f(x)=F'(x)
$$<h3 id="cumulative-distribution-function-3">
<a class="header-anchor" href="#cumulative-distribution-function-3"></a>
Cumulative Distribution Function
</h3>$$
F(x)=\int_{-\infty}^xf(t)dt
$$<h3 id="interval-probability">
<a class="header-anchor" href="#interval-probability"></a>
Interval Probability
</h3>$$
P(a \lt x \le b)=\int_a^bf(x)dx=F(b)-F(a)
$$<p>$\because$ $P(x=a)=0,a \in R$
$\therefore$ The equality signs on the interval can be chosen freely.</p>
<h3 id="normalization">
<a class="header-anchor" href="#normalization"></a>
Normalization
</h3>$$
F(\infty)=\int^{\infty}_{-\infty}f(x)dx=1
$$$$
F(-\infty)=0
$$<h2 id="two-dimensional-discrete-random-variables">
<a class="header-anchor" href="#two-dimensional-discrete-random-variables"></a>
Two-Dimensional Discrete Random Variables
</h2><h3 id="joint-probability-mass-function">
<a class="header-anchor" href="#joint-probability-mass-function"></a>
Joint Probability Mass Function
</h3><p>$P(X=x_i,Y=y_j)$
Create a 2D table of possible values for X and Y, filling in corresponding probabilities.</p>
<h3 id="marginal-probability-mass-function">
<a class="header-anchor" href="#marginal-probability-mass-function"></a>
Marginal Probability Mass Function
</h3><p>$P(X=x_i),P(Y=y_j)$
Sum the rows/columns of the joint probability table to get $f_Y(x),f_X(y)$.</p>
<h3 id="conditional-distribution">
<a class="header-anchor" href="#conditional-distribution"></a>
Conditional Distribution
</h3><p>$P(X=x_i|Y=y_j),P(Y=y_i|X=x_j)$
Divide each row/column of the joint probability table by its marginal probability.
This scales the joint probabilities so each row/column sums to 1.</p>
<h3 id="independence-of-two-variables">
<a class="header-anchor" href="#independence-of-two-variables"></a>
Independence of Two Variables
</h3><p>==Independence here refers to linear independence, not complete statistical independence.==
Write the joint probability table as a matrix $\vec{A}$. If $\det \vec{A}=0$, X and Y are independent.
Or: If the rows/columns of the joint probability table are proportional, X and Y are independent.
Or: If the joint probability $\ne$ the product of marginal probabilities, i.e., $P(X=x_i,Y=y_j)\ne P(X=x_i)P(Y=y_j)$, then X and Y are not independent.</p>
<h2 id="two-dimensional-continuous-random-variables">
<a class="header-anchor" href="#two-dimensional-continuous-random-variables"></a>
Two-Dimensional Continuous Random Variables
</h2><h3 id="joint-density-function">
<a class="header-anchor" href="#joint-density-function"></a>
Joint Density Function
</h3>$$
f(x,y)
$$<h3 id="normalization-1">
<a class="header-anchor" href="#normalization-1"></a>
Normalization
</h3>$$
\int^{\infty}_{-\infty}\int^{\infty}_{-\infty}f(x,y)dxdy=1
$$<h3 id="marginal-density-functions">
<a class="header-anchor" href="#marginal-density-functions"></a>
Marginal Density Functions
</h3>$$
f_X(x)=\int^{\infty}_{-\infty}f(x,y)dy
$$<p>
</p>
$$
f_Y(y)=\int^{\infty}_{-\infty}f(x,y)dx
$$<h3 id="conditional-density">
<a class="header-anchor" href="#conditional-density"></a>
Conditional Density
</h3>$$
f_{Y|X}(y|x)=\frac{f(x,y)}{f_X(x)}
$$<h3 id="independence-1">
<a class="header-anchor" href="#independence-1"></a>
Independence
</h3>$$
f(x,y)=f_X(x)f_Y(y)
$$<p>
When this holds, X and Y are independent.</p>
<h3 id="distribution-function">
<a class="header-anchor" href="#distribution-function"></a>
Distribution Function
</h3><p>Let $Z=X-Y$,
</p>
$$
\begin{align}
F_Z(z)
&=P(Z \lt z)\\
&=P(X-Y \lt z)\\
&=P(X \lt Y+z)\\
&=\int^{y}_{-\infty}\int^{y+z}_{-\infty}f(x,y)dxdy\\
\end{align}
$$<p>
The distribution function $F_Z(z)=\iint_Df(x,y)dxdy$. Differentiate to get the probability density function $f_Z(z)$.
==Warning==: $F_Z(z)$ must satisfy normalization.</p>
<h2 id="expectation-and-variance">
<a class="header-anchor" href="#expectation-and-variance"></a>
Expectation and Variance
</h2><h3 id="relations">
<a class="header-anchor" href="#relations"></a>
Relations
</h3>$$
DX=EX^2-(EX)^2
$$<p>
</p>
$$
D(cX)=c^2DX
$$<p>
</p>
$$
D(X+Y)=D(X)+D(Y)+2Cov(X,Y)
$$<p>
When X and Y are independent, $Cov(X,Y)=0$.</p>
<h3 id="common-expectations-and-variances">
<a class="header-anchor" href="#common-expectations-and-variances"></a>
Common Expectations and Variances
</h3><h4 id="distribution">
<a class="header-anchor" href="#distribution"></a>
$(0,1)$ Distribution
</h4>$$
EX=p,DX=p(1-p)
$$<h4 id="binomial-distribution">
<a class="header-anchor" href="#binomial-distribution"></a>
$B(n,p)$ Binomial Distribution
</h4>$$
EX=np,DX=np(1-p)
$$<h4 id="uniform-distribution-1">
<a class="header-anchor" href="#uniform-distribution-1"></a>
$U(a,b)$ Uniform Distribution
</h4>$$
EX=\frac{a+b}{2},DX=\frac{(b-a)^2}{12}
$$<h4 id="exponential-distribution-1">
<a class="header-anchor" href="#exponential-distribution-1"></a>
$E(\lambda)$ Exponential Distribution
</h4>$$
EX=\frac{1}{\lambda},DX=\frac{1}{\lambda^2}
$$<h4 id="poisson-distribution-1">
<a class="header-anchor" href="#poisson-distribution-1"></a>
$P(\lambda)$ Poisson Distribution
</h4>$$
EX=\lambda,DX=\lambda
$$<h4 id="normal-distribution-1">
<a class="header-anchor" href="#normal-distribution-1"></a>
$N(\mu,\sigma^2)$ Normal Distribution
</h4>$$
EX=\mu,DX=\sigma^2
$$<h2 id="covariance-and-correlation-coefficient">
<a class="header-anchor" href="#covariance-and-correlation-coefficient"></a>
Covariance and Correlation Coefficient
</h2><h3 id="covariance">
<a class="header-anchor" href="#covariance"></a>
Covariance
</h3>$$
Cov(X,Y)=E(XY)-E(X)E(Y)
$$<p>
Clearly, when $X=Y$, $Cov(X,X)=DX$.
</p>
$$
Cov(X+Y,Z)=Cov(X,Z)+Cov(Y,Z)
$$<p>
</p>
$$
Cov(X-Y,Z)=Cov(X,Z)+Cov(-Y,Z)=Cov(X,Z)-Cov(Y,Z)
$$<h3 id="correlation-coefficient">
<a class="header-anchor" href="#correlation-coefficient"></a>
Correlation Coefficient
</h3>$$
\rho_{XY}=\frac{Cov(X,Y)}{\sqrt{DX \cdot DY}}
$$<p>
Higher $|\rho|$ means stronger correlation.
When $Y=X$, $X$ and $X$ are perfectly correlated, $\rho=1$.
When $Y=-X$, $-X$ and $X$ are perfectly correlated, $\rho=-1$.
Clearly $|\rho| \le 1$.
$\rho=0$ means X and Y are uncorrelated.
==Warning==: Uncorrelated $\nRightarrow$ Independent, but Independent $\Rightarrow$ Uncorrelated.</p>
<h2 id="chebyshevs-inequality-for-probability-estimation">
<a class="header-anchor" href="#chebyshevs-inequality-for-probability-estimation"></a>
Chebyshev&rsquo;s Inequality for Probability Estimation
</h2>$$
P(|X-EX|\ge \varepsilon)\le \frac{DX}{\varepsilon^2}
$$<h2 id="central-limit-theorem">
<a class="header-anchor" href="#central-limit-theorem"></a>
Central Limit Theorem
</h2><p>A large number of independent, identically distributed variables can be approximated by a normal distribution.
If $x_1,x_2,\cdots,x_n$ are independent and identically distributed, then
</p>
$$
\sum_{i=1}^nx_i \sim N(\sum^{n}_{i=1}E(x_i),\sum^{n}_{i=1}D(x_i))
$$<h2 id="three-major-distributions">
<a class="header-anchor" href="#three-major-distributions"></a>
Three Major Distributions
</h2><h3 id="chi-squared-distribution">
<a class="header-anchor" href="#chi-squared-distribution"></a>
$\chi^2$ (Chi-Squared) Distribution
</h3>$$
X=x_1^2+x_2^2+\cdots +x_n^2 \sim \chi^2(n),x_i \sim N(0,1) \text{ and independent}
$$<p>
Upper $\alpha$ quantile $\chi^2_\alpha(n)$
Density function is in the first quadrant.</p>
<h3 id="distribution-1">
<a class="header-anchor" href="#distribution-1"></a>
$t$ Distribution
</h3>$$
X=\frac{x_1}{\sqrt{x_2/n}}\sim t(n),x_1 \sim N(0,1),x_2 \sim \chi^2(n),x_1 \text{ and } x_2 \text{ independent}
$$<p>
Upper $\alpha$ quantile $t_\alpha(n)$
Density function resembles normal distribution, symmetric.</p>
<h3 id="distribution-2">
<a class="header-anchor" href="#distribution-2"></a>
$F$ Distribution
</h3>$$
X=\frac{x_1/n_1}{x_2/n_2} \sim F(n_1,n_2),x_1 \sim \chi^2(n_1),x_2 \sim \chi^2(n_2),x_1 \text{ and } x_2 \text{ independent}
$$<p>
Upper $\alpha$ quantile $F_\alpha(n_1,n_2)$
Density function is in the first quadrant.</p>
<h2 id="estimation-methods">
<a class="header-anchor" href="#estimation-methods"></a>
Estimation Methods
</h2><p>For simple random samples that are independent and identically distributed, estimate unknown parameters.</p>
<h3 id="method-of-moments">
<a class="header-anchor" href="#method-of-moments"></a>
Method of Moments
</h3><p>When sample size is large, approximate the sample as uniformly distributed, using sample mean to replace population mean (population moment = sample moment).</p>
<ol>
<li>Calculate the expectation $EX$ (first population moment) from the given probability mass/density function.</li>
<li>Calculate the sample mean $\bar{X}$ (first sample moment) from the given sample.</li>
<li>Set $EX=\bar{X}$ and solve for $\theta_0$ as $\hat{\theta}$.</li>
</ol>
<h3 id="maximum-likelihood-estimation">
<a class="header-anchor" href="#maximum-likelihood-estimation"></a>
Maximum Likelihood Estimation
</h3><p>The estimate maximizes the probability of the observed sample.
Likelihood function for the sample:
</p>
$$
L(x_1,x_2,\cdots,x_n;\theta)=
\begin{cases}
P(X=x_1)P(X=x_2)\cdots P(X=x_n), \text{discrete}\\
f(x_1;\theta)f(x_2;\theta)\cdots f(x_n;\theta), \text{continuous}\\
\end{cases}
$$<p>
To find the maximum of $L$, take the derivative to find critical points. Since the product form is cumbersome, first take the logarithm before differentiating with respect to $\theta$.
</p>
$$
(\ln L)'=
\begin{cases}
(\ln P_1+\ln P_2+\cdots +\ln P_n)', \text{discrete}\\
[\ln f(x_1;\theta)+\ln f(x_2;\theta)+\cdots +\ln f(x_n;\theta)]', \text{continuous}\\
\end{cases}
=0
$$<p>
Solve for the critical point $\theta_0$, which is the estimate $\hat{\theta}$.</p>
<h2 id="unbiasedness-and-efficiency">
<a class="header-anchor" href="#unbiasedness-and-efficiency"></a>
Unbiasedness and Efficiency
</h2><p>If $E(\hat{\theta})=\theta$, then $\hat{\theta}$ is an unbiased estimator of $\theta$.
If $\hat{\theta_1},\hat{\theta_2}$ are both unbiased, and $D(\hat{\theta_1}) \lt \hat{\theta_2}$, then $\hat{\theta_1}$ is more efficient than $\hat{\theta_2}$.</p>
<h2 id="interval-estimation">
<a class="header-anchor" href="#interval-estimation"></a>
Interval Estimation
</h2><p>$X \sim N(\mu,\sigma^2)$, typically given $\bar{X}=\mu,S=\sigma$.
Confidence level: $1-\alpha$, usually $\alpha=5\%$.</p>
<h3 id="confidence-interval-for">
<a class="header-anchor" href="#confidence-interval-for"></a>
Confidence Interval for $\mu$
</h3><h4 id="known">
<a class="header-anchor" href="#known"></a>
$\sigma^2$ Known
</h4><p>Pivotal quantity (standardized):
</p>
$$
\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\sim N(0,1)
$$<p>
</p>
$$
\mu \in (\bar{x}-\frac{\sigma}{\sqrt{n}}\mu_{\frac{\alpha}{2}},\bar{x}+\frac{\sigma}{\sqrt{n}}\mu_{\frac{\alpha}{2}})
$$<h4 id="unknown">
<a class="header-anchor" href="#unknown"></a>
$\sigma^2$ Unknown
</h4><p>Pivotal quantity:
</p>
$$
\frac{\bar{X}-\mu}{S/\sqrt{n}}\sim t(n-1)
$$<p>
</p>
$$
\mu \in (\bar{x}-\frac{S}{\sqrt{n}}t_{\frac{\alpha}{2}}(n-1),\bar{x}+\frac{S}{\sqrt{n}}t_{\frac{\alpha}{2}}(n-1))
$$<h3 id="confidence-interval-for-1">
<a class="header-anchor" href="#confidence-interval-for-1"></a>
Confidence Interval for $\sigma^2$
</h3><p>Usually $\mu$ is unknown.
Pivotal quantity:
</p>
$$
\frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1)
$$<p>
</p>
$$
\sigma^2 \in (\frac{(n-1)S^2}{\chi^2_{\frac{\alpha}{2}}(n-1)},\frac{(n-1)S^2}{\chi^2_{1-\frac{\alpha}{2}}(n-1)}})
$$<h2 id="hypothesis-testing">
<a class="header-anchor" href="#hypothesis-testing"></a>
Hypothesis Testing
</h2><p>Generally, the significance level is set at $\alpha=5\%$.</p>
<h3 id="test-mean-test">
<a class="header-anchor" href="#test-mean-test"></a>
$\mu$ Test (Mean Test)
</h3><ol>
<li>
<p><strong>Hypothesis Formulation</strong><br>
$H_0: \mu = \mu_0$ (null hypothesis)<br>
$H_1: \mu \ne \mu_0$ (alternative hypothesis)</p>
</li>
<li>
<p><strong>Test Statistic Selection</strong></p>
<ul>
<li>When population variance $\sigma^2$ is <strong>known</strong>:<br>
Use $Z = \frac{\bar{X} - \mu}{\sigma / \sqrt{n}} \sim N(0,1)$ (<strong>Z-test</strong>)</li>
<li>When population variance $\sigma^2$ is <strong>unknown</strong>:<br>
Use $T = \frac{\bar{X} - \mu}{S / \sqrt{n}} \sim t(n-1)$ (<strong>T-test</strong>)</li>
</ul>
</li>
<li>
<p><strong>Rejection Region Determination</strong></p>
<ul>
<li>For Z-test:<br>
$W = (-\infty, -z_{\alpha/2}) \cup (z_{\alpha/2}, \infty)$</li>
<li>For T-test:<br>
$W = (-\infty, -t_{\alpha/2}(n-1)) \cup (t_{\alpha/2}(n-1), \infty)$</li>
</ul>
</li>
<li>
<p><strong>Decision Rule</strong><br>
Reject $H_0$ if the computed test statistic falls within the rejection region $W$.</p>
</li>
</ol>
<h3 id="test-variance-test">
<a class="header-anchor" href="#test-variance-test"></a>
$\sigma^2$ Test (Variance Test)
</h3><p>Sample standard deviation formula:<br>
</p>
$$ S = \sqrt{S^2} = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{X})^2} $$<ol>
<li>
<p><strong>Hypothesis Formulation</strong><br>
$H_0: \sigma^2 = \sigma_0^2$<br>
$H_1: \sigma^2 \ne \sigma_0^2$</p>
</li>
<li>
<p><strong>Test Statistic Selection</strong><br>
Use $\chi^2 = \frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$ (<strong>Chi-square test</strong>)</p>
</li>
<li>
<p><strong>Rejection Region Determination</strong><br>
$W = (0, \chi^2_{1-\alpha/2}(n-1)) \cup (\chi^2_{\alpha/2}(n-1), \infty)$</p>
</li>
<li>
<p><strong>Decision Rule</strong><br>
Reject $H_0$ if the test statistic falls within the rejection region $W$.</p>
</li>
</ol>
<h2 id="supplementary-notes">
<a class="header-anchor" href="#supplementary-notes"></a>
Supplementary Notes
</h2><h3 id="properties-of-distribution-functions">
<a class="header-anchor" href="#properties-of-distribution-functions"></a>
Properties of Distribution Functions
</h3><p>For different types of random variables:</p>
<ul>
<li><strong>Continuous random variables</strong>: The distribution function is continuous.</li>
<li><strong>Discrete random variables</strong>: The continuity of the distribution function depends on its definition.</li>
</ul>
<h4 id="left-continuous-definition">
<a class="header-anchor" href="#left-continuous-definition"></a>
Left-Continuous Definition
</h4>$$ F(x) = P(X  \lt  x) $$<p><br>
In this case:</p>
<ul>
<li>$F(x) = F(x^-) = F(x-0) = P(X  \lt  x)$</li>
<li>$F(x^+) = F(x+0) = P(X  \lt  x) + P(X = x)$</li>
</ul>
<p>When $P(X = x) \ne 0$, $F(x^+)  \gt  F(x) = F(x^-)$, making the distribution function <strong>left-continuous but not right-continuous</strong>.</p>
<h4 id="right-continuous-definition">
<a class="header-anchor" href="#right-continuous-definition"></a>
Right-Continuous Definition
</h4>$$ F(x) = P(X \le x) $$<p><br>
In this case:</p>
<ul>
<li>$F(x) = F(x^+) = F(x+0) = P(X \le x)$</li>
<li>$F(x^-) = F(x-0) = P(X \le x) - P(X = x)$</li>
</ul>
<p>When $P(X = x) \ne 0$, $F(x^+) = F(x)  \gt  F(x^-)$, making the distribution function <strong>right-continuous but not left-continuous</strong>.</p>
<h4 id="coin-toss-example">
<a class="header-anchor" href="#coin-toss-example"></a>
Coin Toss Example
</h4><p>Consider a single coin toss:</p>
<ul>
<li>Heads (1): Probability 0.5</li>
<li>Tails (0): Probability 0.5</li>
</ul>
<p>Random variable $X$ has the distribution:<br>
</p>
$$ 
\begin{cases} 
P(X=0) = 0.5 \\ 
P(X=1) = 0.5 \\ 
P(X=\text{other values}) = 0 \\ 
\end{cases} 
$$<p>Cumulative probabilities:<br>
</p>
$$ 
\begin{cases} 
P(X  \lt  0) = 0 \\ 
P(0 \le X  \lt  1) = 0.5 \\ 
P(X \ge 1) = 1 \\ 
\end{cases} 
$$<p>Using the <strong>left-continuous definition</strong> $F(x) = P(X  \lt  x)$:<br>
</p>
$$ 
F(x) = 
\begin{cases} 
0, & x \le 0 \\ 
0.5, & 0  \lt  x \le 1 \\ 
1, & x  \gt  1 \\ 
\end{cases} 
$$<p><br>
Here:</p>
<ul>
<li>$F(0^-) = F(0) = 0$</li>
<li>$F(0^+) = 0.5$</li>
<li>At $x=0$, there is a discontinuity point where the function is <strong>left-continuous but not right-continuous</strong>.</li>
</ul>

        
        <hr><p>Published on 2024-09-10 at <a href='https://guzhengsvt.cn/'>孤筝の温暖小家</a>, last modified on 2024-09-10</p><p>Unless otherwise stated, all posts on this blog are licensed under the BY-NC-SA license. Please credit the source when reposting!</p>]]></description><category>Math</category></item><item><title>Real Number Construction Reading Report</title><link>https://guzhengsvt.cn/en/post/math/%E5%AE%9E%E6%95%B0%E5%BB%BA%E7%AB%8B%E8%AF%BB%E4%B9%A6%E6%8A%A5%E5%91%8A/</link><pubDate>Wed, 27 Dec 2023 21:40:17 +0800</pubDate><author>lvbowen040427@163.com (孤筝)</author><guid>https://guzhengsvt.cn/en/post/math/%E5%AE%9E%E6%95%B0%E5%BB%BA%E7%AB%8B%E8%AF%BB%E4%B9%A6%E6%8A%A5%E5%91%8A/</guid><description>
<![CDATA[<h1>Real Number Construction Reading Report</h1><p>Author: 孤筝 (lvbowen040427@163.com)</p>
        
          <h1 id="foundations-of-real-numbers-book-report">
<a class="header-anchor" href="#foundations-of-real-numbers-book-report"></a>
Foundations of Real Numbers Book Report
</h1><p>Taking advantage of this mathematical analysis assignment, I&rsquo;d like to document the construction of real numbers.</p>
<p>The establishment of real numbers forms part of the foundational theories in mathematics, intersecting with multiple branches such as mathematical logic, set theory, and algebraic structures. Through rigorous derivation of these fundamental concepts and properties, mathematicians have constructed the real number system, providing a solid foundation for mathematical development. This process has evolved over a long history with contributions from numerous mathematicians.</p>
<h2 id="1-book-information">
<a class="header-anchor" href="#1-book-information"></a>
1. Book Information
</h2><h3 id="11-mathematical-analysis">
<a class="header-anchor" href="#11-mathematical-analysis"></a>
1.1 Mathematical Analysis
</h3><ul>
<li><strong>Author:</strong> Tom A. Apostol</li>
<li><strong>Year of Publication:</strong> 1973</li>
<li><strong>Introduction:</strong> <em>Mathematical Analysis</em> is a classic work by Tom M. Apostol, systematically introducing foundational knowledge in mathematical analysis, including the real number system, limits, continuity, and more. With clear logic and profound insight, the author helps readers develop a deep understanding of real numbers.</li>
</ul>
<h3 id="12-real-analysis-and-functional-analysis">
<a class="header-anchor" href="#12-real-analysis-and-functional-analysis"></a>
1.2 Real Analysis and Functional Analysis
</h3><ul>
<li><strong>Author:</strong> Kuang Jichang</li>
<li><strong>Year of Publication:</strong> 2002</li>
<li><strong>Introduction:</strong> <em>Real Analysis and Functional Analysis</em> is an advanced mathematics textbook by Professor Kuang Jichang, primarily covering the basic concepts, theories, and methods of real analysis and functional analysis. A distinctive feature of this book is its integration of traditional real-variable function theory, measure theory, and functional analysis into a modern foundational course using sets and mappings.</li>
</ul>
<h3 id="13-real-and-complex-analysis">
<a class="header-anchor" href="#13-real-and-complex-analysis"></a>
1.3 Real and Complex Analysis
</h3><ul>
<li><strong>Author:</strong> Walter Rudin</li>
<li><strong>Year of Publication:</strong> 2006</li>
<li><strong>Introduction:</strong> This book is a classic in the field of analysis. Its elegant structure and practical utility are complemented by concise and brilliant examples. Both the real and complex analysis sections rigorously prove nearly all propositions presented.</li>
</ul>
<h3 id="14-real-analysis">
<a class="header-anchor" href="#14-real-analysis"></a>
1.4 Real Analysis
</h3><ul>
<li><strong>Author:</strong> Halsey Royden, Patrick Fitzpatrick</li>
<li><strong>Year of Publication:</strong> 2010</li>
<li><strong>Introduction:</strong> This book has become a classic in mathematical analysis, offering students a profound theoretical foundation. The fifth edition includes significant updates, comprehensively covering measure theory, integration theory, and topics essential for modern analysts, such as metric, topological, Hilbert, and Banach spaces.</li>
</ul>
<h2 id="2-the-real-number-system">
<a class="header-anchor" href="#2-the-real-number-system"></a>
2. The Real Number System
</h2><p>The real number system is the cornerstone of mathematical analysis. Apostol&rsquo;s book details the <strong>definition</strong> and <strong>properties</strong> of real numbers. Key features such as <strong>completeness</strong> and <strong>density</strong> make real numbers fundamental to mathematical analysis.</p>
<p>The <strong>construction of real numbers</strong> involves basic mathematical concepts and systematic development. The real number system provides a complete description of quantities, <strong>including integers, rational numbers, and irrational numbers</strong>.</p>
<h3 id="21-introduction-to-rational-numbers">
<a class="header-anchor" href="#21-introduction-to-rational-numbers"></a>
2.1 Introduction to Rational Numbers
</h3><ol>
<li>
<p><strong>Natural Numbers:</strong> The starting point is the natural numbers: 1, 2, 3, 4, &hellip;, used for counting and ordering.</p>
</li>
<li>
<p><strong>Integers:</strong> To address subtraction, zero and negative integers are introduced, forming the integer system: positive integers, zero, and negative integers.</p>
</li>
<li>
<p><strong>Rational Numbers:</strong> While integers solve subtraction, division remains limited. For example, calculating $\frac{1}{3}$ or $\frac{2}{7}$ reveals numbers not expressible as integers. Rational numbers extend the integer system, ensuring any ratio of two integers belongs to this new set. The rational number system addresses gaps in the integer system, ensuring density—between any two rational numbers lies another rational number.</p>
</li>
<li>
<p><strong>Properties of Rational Numbers:</strong> Rational numbers are closed under addition, subtraction, multiplication, and division (except by zero). These properties make rational numbers a complete number system.</p>
</li>
</ol>
<h3 id="22-introduction-to-irrational-numbers">
<a class="header-anchor" href="#22-introduction-to-irrational-numbers"></a>
2.2 Introduction to Irrational Numbers
</h3><ol>
<li>
<p><strong>Limitations of Rational Numbers:</strong> Although rational numbers represent most quantities, some numbers, like $\sqrt{2}$, cannot be expressed as a ratio of integers. No integers $a$ and $b$ satisfy $\frac{a}{b} = \sqrt{2}$.</p>
</li>
<li>
<p><strong>Definition of Irrational Numbers:</strong> To fill this gap, irrational numbers are introduced—numbers <strong>not expressible as ratios of integers</strong>, i.e., non-rational numbers.</p>
</li>
<li>
<p><strong>Transcendental Irrational Numbers:</strong> These are irrational numbers that cannot be roots of any algebraic equation, e.g., $e$ and $\pi$. They cannot be derived through finite algebraic operations.</p>
</li>
</ol>
<h3 id="23-proof-of-real-number-completeness">
<a class="header-anchor" href="#23-proof-of-real-number-completeness"></a>
2.3 Proof of Real Number Completeness
</h3><p>The real number system is complete: any infinite sequence on the real line has a limit. This property is crucial in mathematical analysis, especially for limits, continuity, and convergence.</p>
<h4 id="methods-of-proof">
<a class="header-anchor" href="#methods-of-proof"></a>
Methods of Proof
</h4><h5 id="supremum-principle">
<a class="header-anchor" href="#supremum-principle"></a>
Supremum Principle
</h5><h6 id="definition-of-supremum">
<a class="header-anchor" href="#definition-of-supremum"></a>
Definition of Supremum:
</h6><p>For a set $S$ of real numbers, if a real number $M$ is an upper bound of $S$ and any number less than $M$ is not an upper bound, then $M$ is the supremum of $S$.</p>
<h6 id="example">
<a class="header-anchor" href="#example"></a>
Example:
</h6><p>For $S = \{ x \in \mathbb{R} \mid 0  \lt  x  \lt  1 \}$, the supremum is 1.</p>
<h6 id="completeness-of-real-numbers">
<a class="header-anchor" href="#completeness-of-real-numbers"></a>
Completeness of Real Numbers:
</h6><ul>
<li><strong>Monotone Convergence Theorem:</strong> A bounded monotonic sequence converges.</li>
<li><strong>Existence of Supremum:</strong> Every non-empty bounded set of real numbers has a supremum.</li>
</ul>
<h5 id="monotone-convergence-theorem">
<a class="header-anchor" href="#monotone-convergence-theorem"></a>
Monotone Convergence Theorem
</h5><p>A bounded monotonic (increasing or decreasing) sequence of real numbers has a limit.</p>
<h5 id="nested-interval-theorem">
<a class="header-anchor" href="#nested-interval-theorem"></a>
Nested Interval Theorem
</h5><p>For a sequence of closed intervals $[a_n, b_n]$ where each interval is contained within the previous one, there exists a real number $x$ common to all intervals.</p>
<h5 id="finite-covering-theorem-heine-borel-theorem">
<a class="header-anchor" href="#finite-covering-theorem-heine-borel-theorem"></a>
Finite Covering Theorem (Heine-Borel Theorem)
</h5><p>Any open cover of a closed bounded interval has a finite subcover.</p>
<h5 id="bolzano-weierstrass-theorem">
<a class="header-anchor" href="#bolzano-weierstrass-theorem"></a>
Bolzano-Weierstrass Theorem
</h5><p>Every bounded infinite subset of real numbers has at least one accumulation point.</p>
<h5 id="cauchy-convergence-criterion">
<a class="header-anchor" href="#cauchy-convergence-criterion"></a>
Cauchy Convergence Criterion
</h5><p>A sequence of real numbers converges if and only if it is a Cauchy sequence.</p>
<h3 id="24-algebraic-structure-of-real-numbers">
<a class="header-anchor" href="#24-algebraic-structure-of-real-numbers"></a>
2.4 Algebraic Structure of Real Numbers
</h3><p>The real number system adheres to algebraic properties:</p>
<ol>
<li><strong>Addition:</strong> Commutative, associative, identity element (0), and inverses.</li>
<li><strong>Multiplication:</strong> Commutative, associative, identity element (1), and inverses (for non-zero elements).</li>
<li><strong>Distributive Property:</strong> Multiplication distributes over addition.</li>
<li><strong>Order Relation:</strong> Real numbers are ordered, with properties like transitivity and antisymmetry.</li>
</ol>
<p>These properties make real numbers an ordered field, providing robust tools for mathematical analysis.</p>
<h2 id="3-limits-and-continuity">
<a class="header-anchor" href="#3-limits-and-continuity"></a>
3. Limits and Continuity
</h2><p>Limits and continuity are central to mathematical analysis.</p>
<h3 id="31-limits-of-real-numbers">
<a class="header-anchor" href="#31-limits-of-real-numbers"></a>
3.1 Limits of Real Numbers
</h3><h4 id="definition">
<a class="header-anchor" href="#definition"></a>
Definition:
</h4><p>A sequence $\{a_n\}$ converges to $L$ if, for any $\varepsilon \gt 0$, there exists $N$ such that for all $n \gt N$, $|a_n - L|  \lt  \varepsilon$.</p>
<h4 id="example-1">
<a class="header-anchor" href="#example-1"></a>
Example:
</h4><p>$\lim_{n \to \infty} \frac{1}{n} = 0$.</p>
<h4 id="properties">
<a class="header-anchor" href="#properties"></a>
Properties:
</h4><ul>
<li>Uniqueness of limits.</li>
<li>Bounded monotonic sequences converge.</li>
</ul>
<h3 id="32-continuity-of-real-numbers">
<a class="header-anchor" href="#32-continuity-of-real-numbers"></a>
3.2 Continuity of Real Numbers
</h3><h4 id="definition-1">
<a class="header-anchor" href="#definition-1"></a>
Definition:
</h4><p>A function $f(x)$ is continuous at $x = a$ if:</p>
<ol>
<li>$f(a)$ exists.</li>
<li>$\lim_{x \to a} f(x)$ exists.</li>
<li>$\lim_{x \to a} f(x) = f(a)$.</li>
</ol>
<h4 id="properties-1">
<a class="header-anchor" href="#properties-1"></a>
Properties:
</h4><ul>
<li>Sums, products, and compositions of continuous functions are continuous.</li>
</ul>
<h3 id="33-key-theorems">
<a class="header-anchor" href="#33-key-theorems"></a>
3.3 Key Theorems
</h3><h4 id="intermediate-value-theorem">
<a class="header-anchor" href="#intermediate-value-theorem"></a>
Intermediate Value Theorem:
</h4><p>If $f$ is continuous on $[a, b]$ and $f(a) \neq f(b)$, then for any $c$ between $f(a)$ and $f(b)$, there exists $x_0 \in (a, b)$ such that $f(x_0) = c$.</p>
<h4 id="extreme-value-theorem">
<a class="header-anchor" href="#extreme-value-theorem"></a>
Extreme Value Theorem:
</h4><p>A continuous function on a closed interval attains its maximum and minimum.</p>
<h2 id="4-comparative-analysis">
<a class="header-anchor" href="#4-comparative-analysis"></a>
4. Comparative Analysis
</h2><h3 id="41-mathematical-analysis">
<a class="header-anchor" href="#41-mathematical-analysis"></a>
4.1 <strong>Mathematical Analysis</strong>:
</h3><ul>
<li>Covers basic real analysis: construction of real numbers, continuity, limits, derivatives, and integrals.</li>
<li>Emphasizes mathematical logic and set theory.<br>
<img src="https://cdn.jsdelivr.net/gh/GuZhengSVT/Hugo-media/2023/12/330423610.png" alt="Mathematical Analysis-1.png"></li>
</ul>
<h3 id="42-real-analysis-and-functional-analysis">
<a class="header-anchor" href="#42-real-analysis-and-functional-analysis"></a>
4.2 <strong>Real Analysis and Functional Analysis</strong>:
</h3><ul>
<li>Discusses advanced constructions like Dedekind cuts.</li>
<li>Includes measure theory and functional analysis basics.<br>
<img src="https://cdn.jsdelivr.net/gh/GuZhengSVT/Hugo-media/2023/12/1611562658.png" alt="实分析与泛函分析-1.png"></li>
</ul>
<h3 id="43-real-and-complex-analysis">
<a class="header-anchor" href="#43-real-and-complex-analysis"></a>
4.3 <strong>Real and Complex Analysis</strong>:
</h3><ul>
<li>Comprehensive coverage of real and complex analysis.</li>
<li>Highlights measure theory and holomorphic functions.<br>
<img src="https://cdn.jsdelivr.net/gh/GuZhengSVT/Hugo-media/2023/12/3544421365.png" alt="实分析与复分析-1.png"></li>
</ul>
<h3 id="44-real-analysis">
<a class="header-anchor" href="#44-real-analysis"></a>
4.4 <strong>Real Analysis</strong>:
</h3><ul>
<li>Focuses on the real number system&rsquo;s construction and completeness.</li>
<li>Explores metric spaces for deeper understanding.<br>
<img src="https://cdn.jsdelivr.net/gh/GuZhengSVT/Hugo-media/2023/12/2948448354.png" alt="Real Analysis-1.png"></li>
</ul>
<h2 id="7-personal-reflection">
<a class="header-anchor" href="#7-personal-reflection"></a>
7. Personal Reflection
</h2><p>Studying the construction of real numbers has expanded my mathematical perspective. Understanding the transition from rational to irrational numbers and proofs like the supremum principle has deepened my appreciation for the completeness of real numbers.</p>
<p>The concepts of limits and continuity reveal a profound and elegant aspect of mathematics. Limits provide tools for analyzing trends, while continuity ensures smooth transitions in functions, forming the backbone of mathematical analysis.</p>

        
        <hr><p>Published on 2023-12-27 at <a href='https://guzhengsvt.cn/'>孤筝の温暖小家</a>, last modified on 2023-12-27</p><p>Unless otherwise stated, all posts on this blog are licensed under the BY-NC-SA license. Please credit the source when reposting!</p>]]></description><category>Math</category></item><item><title>The Relationship Between the Residue Theorem and Laurent Series, Higher-Order Derivative Formulas, and Cauchy's Integral Formula</title><link>https://guzhengsvt.cn/en/post/math/%E7%95%99%E6%95%B0%E5%AE%9A%E7%90%86%E4%B8%8E%E6%B4%9B%E6%9C%97%E7%BA%A7%E6%95%B0%E9%AB%98%E9%98%B6%E5%AF%BC%E6%95%B0%E5%85%AC%E5%BC%8F%E5%92%8C%E6%9F%AF%E8%A5%BF%E7%A7%AF%E5%88%86%E5%85%AC%E5%BC%8F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%E6%88%96%E8%81%94%E7%B3%BB/</link><pubDate>Wed, 20 Dec 2023 08:54:33 +0800</pubDate><author>lvbowen040427@163.com (孤筝)</author><guid>https://guzhengsvt.cn/en/post/math/%E7%95%99%E6%95%B0%E5%AE%9A%E7%90%86%E4%B8%8E%E6%B4%9B%E6%9C%97%E7%BA%A7%E6%95%B0%E9%AB%98%E9%98%B6%E5%AF%BC%E6%95%B0%E5%85%AC%E5%BC%8F%E5%92%8C%E6%9F%AF%E8%A5%BF%E7%A7%AF%E5%88%86%E5%85%AC%E5%BC%8F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%E6%88%96%E8%81%94%E7%B3%BB/</guid><description>
<![CDATA[<h1>The Relationship Between the Residue Theorem and Laurent Series, Higher-Order Derivative Formulas, and Cauchy's Integral Formula</h1><p>Author: 孤筝 (lvbowen040427@163.com)</p>
        
          <h3 id="1-residue-theorem">
<a class="header-anchor" href="#1-residue-theorem"></a>
1. Residue Theorem
</h3><p>The Residue Theorem is a pivotal result in complex function theory, built upon the concept of residues. Its core idea states that if a function is analytic everywhere on and within a closed contour enclosing isolated singularities, the integral around the contour equals the sum of the residues at those singularities.</p>
<h3 id="2-laurent-series">
<a class="header-anchor" href="#2-laurent-series"></a>
2. Laurent Series
</h3><p>A Laurent series is an expansion of a complex function into an infinite series, including both positive and negative powers. Specifically, a complex function in an annular region can be expressed as:<br>
</p>
$$f(z) = \sum_{n=-\infty}^{\infty} c_n (z - z_0)^n$$<p>Here, \( c_n \) are the coefficients, and \( z_0 \) is the expansion point.</p>
<h3 id="3-higher-order-derivative-formula">
<a class="header-anchor" href="#3-higher-order-derivative-formula"></a>
3. Higher-Order Derivative Formula
</h3><p>The higher-order derivative formula for complex functions resembles that of real functions but requires careful consideration in the complex plane. If a function is analytic at a point, its higher-order derivatives at that point can be obtained by term-wise differentiation of its power series.</p>
<h3 id="4-cauchys-integral-formula">
<a class="header-anchor" href="#4-cauchys-integral-formula"></a>
4. Cauchy&rsquo;s Integral Formula
</h3><p>Cauchy&rsquo;s Integral Formula is a fundamental result in complex analysis, establishing a relationship between an analytic function and its integral over a contour. Specifically, if \( f(z) \) is analytic inside and on a simple closed contour \( C \), then for any point \( z_0 \) inside \( C \):</p>
$$f(z_0) = \frac{1}{2\pi i} \oint_C \frac{f(z)}{z - z_0} \, dz$$<h3 id="relationships-and-connections">
<a class="header-anchor" href="#relationships-and-connections"></a>
Relationships and Connections
</h3><ol>
<li>
<p><strong>Residue Theorem and Laurent Series</strong>:<br>
The Residue Theorem computes integrals over closed contours, while the Laurent series helps analyze the behavior of functions near singularities, facilitating residue calculation.</p>
</li>
<li>
<p><strong>Residue Theorem and Higher-Order Derivatives</strong>:<br>
The Residue Theorem can derive higher-order derivatives by term-wise differentiation of the Laurent series expansion around singularities.</p>
</li>
<li>
<p><strong>Residue Theorem and Cauchy&rsquo;s Integral Formula</strong>:<br>
Cauchy&rsquo;s Integral Formula evaluates contour integrals, while the Residue Theorem is a special case where the contour encloses finitely many isolated singularities.</p>
</li>
</ol>
<hr>
<h3 id="1-proof-of-the-residue-theorem-via-laurent-series">
<a class="header-anchor" href="#1-proof-of-the-residue-theorem-via-laurent-series"></a>
1. Proof of the Residue Theorem via Laurent Series
</h3><h4 id="residue-theorem">
<a class="header-anchor" href="#residue-theorem"></a>
Residue Theorem:
</h4><p>If \( f(z) \) is analytic everywhere inside and on a closed contour \( C \) except for isolated singularities, then:<br>
</p>
$$\oint_C f(z) \, dz = 2\pi i \cdot \sum \text{Res}(f, z_k)$$<h4 id="laurent-series-expansion">
<a class="header-anchor" href="#laurent-series-expansion"></a>
Laurent Series Expansion:
</h4>$$f(z) = \sum_{n=-\infty}^{\infty} c_n (z - z_0)^n$$<h4 id="proof-steps">
<a class="header-anchor" href="#proof-steps"></a>
Proof Steps:
</h4><ol>
<li>
<p><strong>Laurent Series Expansion</strong>:<br>
Expand \( f(z) \) around \( z_0 \):<br>
</p>
$$f(z) = \sum_{n=-\infty}^{\infty} c_n (z - z_0)^n$$</li>
<li>
<p><strong>Integral Computation</strong>:<br>
Integrate term-wise over \( C \):<br>
</p>
$$\oint_C f(z) \, dz = \oint_C \left( \sum_{n=-\infty}^{\infty} c_n (z - z_0)^n \right) dz$$</li>
<li>
<p><strong>Interchange Sum and Integral</strong>:<br>
By uniform convergence:<br>
</p>
$$\oint_C f(z) \, dz = \sum_{n=-\infty}^{\infty} c_n \oint_C (z - z_0)^n \, dz$$</li>
<li>
<p><strong>Residue Extraction</strong>:<br>
For \( n \neq -1 \), \( \oint_C (z - z_0)^n \, dz = 0 \). Only \( n = -1 \) contributes:<br>
</p>
$$\oint_C f(z) \, dz = 2\pi i \cdot c_{-1}$$</li>
<li>
<p><strong>Conclusion</strong>:<br>
The residue \( \text{Res}(f, z_0) = c_{-1} \), yielding:<br>
</p>
$$\oint_C f(z) \, dz = 2\pi i \cdot \text{Res}(f, z_0)$$</li>
</ol>
<hr>
<h3 id="2-deriving-the-higher-order-derivative-formula-from-the-residue-theorem">
<a class="header-anchor" href="#2-deriving-the-higher-order-derivative-formula-from-the-residue-theorem"></a>
2. Deriving the Higher-Order Derivative Formula from the Residue Theorem
</h3><h4 id="residue-theorem-1">
<a class="header-anchor" href="#residue-theorem-1"></a>
Residue Theorem:
</h4>$$\oint_C f(z) \, dz = 2\pi i \cdot \text{Res}(f, z_0)$$<h4 id="higher-order-derivative-formula">
<a class="header-anchor" href="#higher-order-derivative-formula"></a>
Higher-Order Derivative Formula:
</h4><p>For \( f(z) \) analytic at \( z_0 \), the \( n \)-th derivative is:<br>
</p>
$$f^{(n)}(z_0) = \frac{n!}{2\pi i} \oint_C \frac{f(z)}{(z - z_0)^{n+1}} \, dz$$<h4 id="proof-steps-1">
<a class="header-anchor" href="#proof-steps-1"></a>
Proof Steps:
</h4><ol>
<li>
<p><strong>Residue Theorem Setup</strong>:<br>
Consider \( g(z) = \frac{f(z)}{(z - z_0)^{n+1}} \). Its residue at \( z_0 \) is:<br>
</p>
$$\text{Res}(g, z_0) = \frac{f^{(n)}(z_0)}{n!}$$</li>
<li>
<p><strong>Apply Residue Theorem to \( g(z) \)</strong>:<br>
</p>
$$\oint_C \frac{f(z)}{(z - z_0)^{n+1}} \, dz = 2\pi i \cdot \text{Res}(g, z_0) = 2\pi i \cdot \frac{f^{(n)}(z_0)}{n!}$$</li>
<li>
<p><strong>Solve for \( f^{(n)}(z_0) \)</strong>:<br>
</p>
$$f^{(n)}(z_0) = \frac{n!}{2\pi i} \oint_C \frac{f(z)}{(z - z_0)^{n+1}} \, dz$$</li>
</ol>
<hr>
<h3 id="3-proving-cauchys-integral-formula-via-the-residue-theorem">
<a class="header-anchor" href="#3-proving-cauchys-integral-formula-via-the-residue-theorem"></a>
3. Proving Cauchy&rsquo;s Integral Formula via the Residue Theorem
</h3><h4 id="residue-theorem-2">
<a class="header-anchor" href="#residue-theorem-2"></a>
Residue Theorem:
</h4>$$\oint_C f(z) \, dz = 2\pi i \cdot \text{Res}(f, z_0)$$<h4 id="cauchys-integral-formula">
<a class="header-anchor" href="#cauchys-integral-formula"></a>
Cauchy&rsquo;s Integral Formula:
</h4>$$f(z_0) = \frac{1}{2\pi i} \oint_C \frac{f(z)}{z - z_0} \, dz$$<h4 id="proof-steps-2">
<a class="header-anchor" href="#proof-steps-2"></a>
Proof Steps:
</h4><ol>
<li>
<p><strong>Identify the Residue</strong>:<br>
For \( g(z) = \frac{f(z)}{z - z_0} \), the residue at \( z_0 \) is \( \text{Res}(g, z_0) = f(z_0) \).</p>
</li>
<li>
<p><strong>Apply the Residue Theorem</strong>:<br>
</p>
$$\oint_C \frac{f(z)}{z - z_0} \, dz = 2\pi i \cdot \text{Res}(g, z_0) = 2\pi i \cdot f(z_0)$$</li>
<li>
<p><strong>Solve for \( f(z_0) \)</strong>:<br>
</p>
$$f(z_0) = \frac{1}{2\pi i} \oint_C \frac{f(z)}{z - z_0} \, dz$$</li>
</ol>

        
        <hr><p>Published on 2023-12-20 at <a href='https://guzhengsvt.cn/'>孤筝の温暖小家</a>, last modified on 2023-12-20</p><p>Unless otherwise stated, all posts on this blog are licensed under the BY-NC-SA license. Please credit the source when reposting!</p>]]></description><category>Math</category></item><item><title>Complex Analysis</title><link>https://guzhengsvt.cn/en/post/math/%E5%A4%8D%E5%8F%98%E5%87%BD%E6%95%B0/</link><pubDate>Fri, 17 Nov 2023 19:42:47 +0800</pubDate><author>lvbowen040427@163.com (孤筝)</author><guid>https://guzhengsvt.cn/en/post/math/%E5%A4%8D%E5%8F%98%E5%87%BD%E6%95%B0/</guid><description>
<![CDATA[<h1>Complex Analysis</h1><p>Author: 孤筝 (lvbowen040427@163.com)</p>
        
          <h1 id="complex-numbers">
<a class="header-anchor" href="#complex-numbers"></a>
Complex Numbers
</h1><ol>
<li>Representation of complex numbers: $$z = r\cdot e^{i\theta} = r(\cos\theta +i\cdot \sin\theta)$$</li>
<li>Elementary functions
<ol>
<li>Exponential function: $e^z = e^x(\cos y + i \sin y)$
<ol>
<li>$e^z$ is merely shorthand for $\exp z$ and does not imply exponentiation.</li>
<li>$|e^z| = e^x$, $\text{Arg}(e^z) = y + 2k\pi$</li>
</ol>
</li>
<li>Logarithmic function: $\text{Ln}\,z = \ln|r| + i\,\text{Arg}\,z$
<ol>
<li>The function is analytic everywhere except at the origin and the negative real axis, and $(\text{Ln}\,z)' = \frac{1}{z}$.</li>
</ol>
</li>
<li>Trigonometric functions
<ol>
<li>$\cos z = \frac{e^{iz} + e^{-iz}}{2}$, $\sin z = \frac{e^{iz} - e^{-iz}}{2i}$</li>
<li>$\text{ch}\,z = \frac{e^z + e^{-z}}{2}$, $\text{sh}\,z = \frac{e^z - e^{-z}}{2}$</li>
</ol>
</li>
</ol>
</li>
</ol>
<h1 id="analytic-functions">
<a class="header-anchor" href="#analytic-functions"></a>
Analytic Functions
</h1><ol>
<li>Definition of differentiability:<br>
$$\lim_{\Delta z \to 0} \frac{f(z_0 + \Delta z) - f(z_0)}{\Delta z} \text{ exists, then } f(z) \text{ is differentiable at } z_0.$$</li>
<li>Definition of analyticity:<br>
$$f(z) \text{ is analytic at } z_0 \text{ if it is differentiable at } z_0 \text{ and in some neighborhood of } z_0.$$<br>
Corollary: The sum, difference, product, and quotient of analytic functions are also analytic. The composition of analytic functions is analytic.</li>
<li>Necessary and sufficient conditions for differentiability and analyticity:<br>
$u(x, y)$ and $v(x, y)$ are differentiable and satisfy the <strong>Cauchy-Riemann equations</strong>:<br>
$$\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}, \quad \frac{\partial u}{\partial y} = -\frac{\partial v}{\partial x}.$$<br>
If either condition fails, the function is neither differentiable nor analytic.<br>
Corollary:<br>
$$f'(z) = \frac{\partial u}{\partial x} + i \frac{\partial v}{\partial x} = \frac{1}{i} \frac{\partial u}{\partial y} + \frac{\partial v}{\partial y}.$$</li>
</ol>
<h1 id="complex-integration">
<a class="header-anchor" href="#complex-integration"></a>
Complex Integration
</h1><p><strong>Key Formula</strong><br>
</p>
$$\oint_{|z - z_0| = r} \frac{1}{(z - z_0)^n} dz = \begin{cases}  
2\pi i, & n = 1 \\  
0, & n \neq 1  
\end{cases}$$<ol>
<li>Cauchy-Goursat Theorem<br>
For a <strong>simply connected, analytic</strong> region, the integral over any closed contour is zero:<br>
$$\oint_C f(z) dz = 0.$$</li>
<li>Composite Contour Theorem—Extension to <strong>multiply connected</strong> regions<br>
Let $C$ be a simple closed curve in an analytic, multiply connected region, and $C_1, C_2, \dots, C_n$ be simple closed curves inside $C$ with the same orientation. Then:<br>
$$\oint_C f(z) dz = \sum_{k=1}^n \oint_{C_k} f(z) dz.$$</li>
<li>Cauchy Integral Formula—Expressing the value of a function inside a contour in terms of its boundary values<br>
If $f(z)$ is analytic in a region $D$ and $C$ is a positively oriented simple closed curve in $D$:<br>
$$2\pi i \cdot f(z_0) = \oint_C \frac{f(z)}{z - z_0} dz.$$</li>
<li>Generalized Cauchy Integral Formula—Using higher-order derivatives to compute integrals<br>
$$f^{(n)}(z_0) = \frac{n!}{2\pi i} \oint_C \frac{f(z)}{(z - z_0)^{n+1}} dz.$$</li>
</ol>
<h1 id="series">
<a class="header-anchor" href="#series"></a>
Series
</h1><h2 id="power-series">
<a class="header-anchor" href="#power-series"></a>
Power Series
</h2><ol>
<li>Two properties of analytic functions
<ol>
<li>Analytic functions have derivatives of all orders.</li>
<li>Every analytic function can be represented by a power series.</li>
</ol>
</li>
<li>Taylor expansion:<br>
$$f(z) = \sum_{n=0}^\infty \frac{f^{(n)}(0)}{n!} z^n.$$</li>
<li>Methods for finding Taylor expansions [[Advanced Mathematics#Expansion of Functions into Power Series]]</li>
</ol>
<h2 id="laurent-series">
<a class="header-anchor" href="#laurent-series"></a>
Laurent Series
</h2><ol>
<li>Bilateral power series
<ol>
<li>The region of convergence is an annulus $R_1  \lt  |z - z_0|  \lt  R_2$.</li>
</ol>
</li>
<li>Laurent expansion:<br>
$$f(z) = \sum_{n=-\infty}^\infty c_n (z - z_0)^n, \quad c_n = \frac{1}{2\pi i} \oint_C \frac{f(z)}{(z - z_0)^{n+1}} dz.$$<br>
Corollary: When $n = -1$, $c_{-1} \cdot 2\pi i = \oint_C f(z) dz$.</li>
<li>Methods for finding Laurent expansions
<ol>
<li>Compute $c_n$ directly using the definition (rarely used).</li>
<li>Use algebraic operations or substitutions to transform the Laurent series into the <strong>form and convergence domain</strong> of a Taylor series.</li>
</ol>
</li>
</ol>
<h1 id="residues">
<a class="header-anchor" href="#residues"></a>
Residues
</h1><h2 id="isolated-singularities">
<a class="header-anchor" href="#isolated-singularities"></a>
Isolated Singularities
</h2><ol>
<li>Definition: $f(z)$ is not analytic at $z_0$ but is analytic in some punctured neighborhood of $z_0$.</li>
<li>Classification of isolated singularities (based on negative power terms in the Laurent series)
<ol>
<li>Removable singularity: No negative power terms. As $z \to z_0$, $f(z)$ approaches a finite limit.</li>
<li>Pole: Finite number of negative power terms (if there are $m$ such terms, $z_0$ is called an $m$-th order pole). As $z \to z_0$, $f(z) \to \infty$.</li>
<li>Essential singularity: Infinite number of negative power terms. The limit of $f(z)$ does not exist.</li>
</ol>
</li>
<li>Relationship between poles and zeros
<ol>
<li>Definition of zeros: For a non-zero analytic function $f(z)$, if it can be expressed as $f(z) = (z - z_0)^m \varphi(z)$, then $z_0$ is called an $m$-th order zero of $f(z)$.<br>
Necessary and sufficient condition: $f^{(n)}(z_0) = 0$ for $n  \lt  m$, and $f^{(m)}(z_0) \neq 0$.</li>
<li>If $z_0$ is an $m$-th order zero of $f(z)$, then $z_0$ is an $m$-th order pole of $\frac{1}{f(z)}$.</li>
</ol>
</li>
</ol>
<h2 id="residues-1">
<a class="header-anchor" href="#residues-1"></a>
Residues
</h2><ol>
<li>Definition:<br>
$$\text{Res}[f(z), z_0] = c_{-1} = \frac{1}{2\pi i} \oint_C f(z) dz.$$</li>
<li>Rules for computing residues
<ol>
<li>If $z_0$ is a simple pole of $f(z)$:<br>
$$\text{Res}[f(z), z_0] = \lim_{z \to z_0} (z - z_0) f(z).$$</li>
<li>If $z_0$ is an $m$-th order pole of $f(z)$:<br>
$$\text{Res}[f(z), z_0] = \frac{1}{(m-1)!} \lim_{z \to z_0} \frac{d^{m-1}}{dz^{m-1}} \left( (z - z_0)^m f(z) \right).$$</li>
<li>If $f(z) = \frac{P(z)}{Q(z)}$, where $P(z_0) \neq 0$, $Q(z_0) = 0$, and $Q'(z_0) \neq 0$:<br>
$$\text{Res}[f(z), z_0] = \frac{P(z_0)}{Q'(z_0)}.$$</li>
<li></li>
</ol>
</li>
</ol>
$$\text{Res}[f(z), \infty] = -\text{Res}\left[ f\left( \frac{1}{z} \right) \cdot \frac{1}{z^2}, 0 \right].$$
        
        <hr><p>Published on 2023-11-17 at <a href='https://guzhengsvt.cn/'>孤筝の温暖小家</a>, last modified on 2023-11-17</p><p>Unless otherwise stated, all posts on this blog are licensed under the BY-NC-SA license. Please credit the source when reposting!</p>]]></description><category>Math</category></item></channel></rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Thermodynamics and Statistical Physics on 孤筝の温暖小家</title>
    <link>https://guzhengsvt.cn/en/tags/thermodynamics-and-statistical-physics/</link>
    <description>Recent content from 孤筝の温暖小家</description>
    <generator>Hugo</generator>
    <language>en</language>
    
    <managingEditor>lvbowen040427@163.com (孤筝)</managingEditor>
    <webMaster>lvbowen040427@163.com (孤筝)</webMaster>
    
    <copyright>Unless otherwise stated, all posts on this blog are licensed under the BY-NC-SA license. Please credit the source when reposting!</copyright>
    
    <lastBuildDate>Thu, 06 Jun 2024 00:00:59 +0800</lastBuildDate>
    
    
    <atom:link href="https://guzhengsvt.cn/en/tags/thermodynamics-and-statistical-physics/index.xml" rel="self" type="application/rss&#43;xml" />
    

    
      
      
      
    

    <item>
      <title>Thermodynamics and Statistical Physics</title>
      <link>https://guzhengsvt.cn/en/post/physics/%E7%83%AD%E5%8A%9B%E5%AD%A6%E4%B8%8E%E7%BB%9F%E8%AE%A1%E7%89%A9%E7%90%86/</link>
      <pubDate>Thu, 06 Jun 2024 00:00:59 &#43;0800</pubDate>
      <author>lvbowen040427@163.com (孤筝)</author>
      <guid>https://guzhengsvt.cn/en/post/physics/%E7%83%AD%E5%8A%9B%E5%AD%A6%E4%B8%8E%E7%BB%9F%E8%AE%A1%E7%89%A9%E7%90%86/</guid>
      <description>
        <![CDATA[<h1>Thermodynamics and Statistical Physics</h1><p>Author: 孤筝 (lvbowen040427@163.com)</p>
        
          <h1 id="physical-quantities">
<a class="header-anchor" href="#physical-quantities"></a>
Physical Quantities
</h1><h2 id="internal-energy-u">
<a class="header-anchor" href="#internal-energy-u"></a>
Internal Energy U
</h2>$$
\Delta U=Q+W
$$<p>
Q is the heat absorbed by the system, W is the work done by the system</p>
<h2 id="entropy-s">
<a class="header-anchor" href="#entropy-s"></a>
Entropy S
</h2><p>Entropy is a measure of the total amount of energy that <strong>cannot perform work</strong> in terms of dynamics. That is, when the total entropy increases, the ability to perform work decreases, and the measure of entropy is an indicator of energy degradation.<br>
In a ==reversible process==<br>
</p>
$$
\Delta S=\frac {Q}{T}
$$<p><br>
Q: In a reversible process, the system absorbs heat at a constant temperature.</p>
<h2 id="焓-h">
<a class="header-anchor" href="#%e7%84%93-h"></a>
焓 H
</h2>$$
H=U+pV
$$<h2 id="free-energy-f">
<a class="header-anchor" href="#free-energy-f"></a>
Free Energy F
</h2>$$
F=U-TS
$$<p>
Internal energy of the system - energy that cannot do work = energy that can do work (free energy)</p>
<h2 id="gibbs-function-free-enthalpy-g">
<a class="header-anchor" href="#gibbs-function-free-enthalpy-g"></a>
Gibbs Function (Free Enthalpy) G
</h2>$$
G=F+pV=U-TS+pV=H-TS
$$<h2 id="chemical-potential">
<a class="header-anchor" href="#chemical-potential"></a>
Chemical Potential $\mu$
</h2>$$
\mu=(\frac{\partial G}{\partial n})_{T,p}=G_m
$$<p>
Where:</p>
<ul>
<li>n: Amount of substance ($mol$)</li>
<li>$G_m$: Molar Gibbs function</li>
</ul>
<h1 id="equation">
<a class="header-anchor" href="#equation"></a>
Equation
</h1><h2 id="state-function-total-differential-reversible-process">
<a class="header-anchor" href="#state-function-total-differential-reversible-process"></a>
State Function Total Differential (Reversible Process)
</h2><h1 id="">
<a class="header-anchor" href="#"></a>

</h1><h2 id="total-differential-of-internal-energy-fundamental-equation-of-thermodynamics">
<a class="header-anchor" href="#total-differential-of-internal-energy-fundamental-equation-of-thermodynamics"></a>
Total Differential of Internal Energy (Fundamental Equation of Thermodynamics)
</h2>$$
dU=dQ+dW=TdS-pdV
$$<p>
i.e., $U=U(S,V)$
</p>
$$
(\frac{\partial U}{\partial S})_V=T,(\frac{\partial U}{\partial V})_S=-p
$$<p>
$\because$ The second-order partial derivatives of U are equal<br>
$\therefore$ We obtain the <strong>first Maxwell relation</strong>:
</p>
$$
(\frac{\partial T}{\partial V})_S=-(\frac{\partial p}{\partial S})_V
$$<h2 id="enthalpy-total-differential">
<a class="header-anchor" href="#enthalpy-total-differential"></a>
Enthalpy Total Differential
</h2>$$
dH=dU+d(pV)=TdS-pdV+pdV+Vdp=TdS+Vdp
$$<h2 id="differential-of-free-energy">
<a class="header-anchor" href="#differential-of-free-energy"></a>
Differential of Free Energy
</h2>$$
dF=-SdT-pdV
$$<h2 id="gibbs-function-total-differential">
<a class="header-anchor" href="#gibbs-function-total-differential"></a>
Gibbs Function Total Differential
</h2>$$
dG=-SdT+Vdp
$$<h2 id="total-differential-of-entropy">
<a class="header-anchor" href="#total-differential-of-entropy"></a>
Total Differential of Entropy
</h2>$$
dS=\frac{dU+pdV}{T}
$$<h2 id="maxwell-relations">
<a class="header-anchor" href="#maxwell-relations"></a>
Maxwell Relations
</h2><p>The Maxwell Relations are important equations in thermodynamics that describe the relationships between state variables.<br>
Here are the four Maxwell Relations:</p>
<ol>
<li>
<p><strong>First Maxwell Relation</strong>:
</p>
$$
\left ( \frac{\partial T}{\partial V} \right)_S = - \left ( \frac{\partial P}{\partial S} \right)_V
$$</li>
<li>
<p><strong>Second Maxwell Relation</strong>:
</p>
$$
\left ( \frac{\partial T}{\partial P} \right)_S = \left ( \frac{\partial V}{\partial S} \right)_P
$$</li>
<li>
<p><strong>Third Maxwell Relation</strong>:
</p>
$$
\left ( \frac{\partial S}{\partial V} \right)_T = \left ( \frac{\partial P}{\partial T} \right)_V
$$</li>
<li>
<p><strong>Fourth Maxwell Relation</strong>:
</p>
$$
\left ( \frac{\partial S}{\partial P} \right)_T = -\left ( \frac{\partial V}{\partial T} \right)_P
$$</li>
</ol>
<p><strong>Corollary</strong>:
</p>
$$
C_p-C_V=T(\frac{\partial p}{\partial T})_V(\frac{\partial V}{\partial T})_p
$$<p>For an ideal gas $pV=nRT$, substituting yields:
</p>
$$
C_p-C_V=nR, \text{which is a constant.}
$$<h2 id="equation-of-state">
<a class="header-anchor" href="#equation-of-state"></a>
Equation of State
</h2><p>Definition: The functional relationship equation between temperature and state parameters.
</p>
$$
f(p,V,T)=0
$$<h2 id="ideal-gas-equation-of-state">
<a class="header-anchor" href="#ideal-gas-equation-of-state"></a>
Ideal Gas Equation of State
</h2>$$
pV=nRT=NkT
$$<ul>
<li>n: Amount of substance</li>
<li>R: Gas constant</li>
<li>N: Total number of particles in the system</li>
<li>k: Boltzmann constant</li>
</ul>
<h2 id="van-der-waals-equation">
<a class="header-anchor" href="#van-der-waals-equation"></a>
Van der Waals Equation
</h2>$$
(p+\frac{an^2}{V^2})(V-nb)=nRT
$$<ul>
<li>a、b are constants</li>
</ul>
<h2 id="common-coefficients">
<a class="header-anchor" href="#common-coefficients"></a>
Common Coefficients
</h2><h2 id="coefficient-of-volume-expansion">
<a class="header-anchor" href="#coefficient-of-volume-expansion"></a>
Coefficient of Volume Expansion $\alpha$
</h2>$$
\alpha=\frac{1}{V}(\frac{\partial V}{\partial T})_p=\frac{1}{T}, \text{ideal gas}
$$<h1 id="">
<a class="header-anchor" href="#"></a>

</h1><h2 id="pressure-coefficient">
<a class="header-anchor" href="#pressure-coefficient"></a>
Pressure Coefficient $\beta$
</h2>$$
\beta=\frac{1}{V}(\frac{\partial p}{\partial T})_V=\frac{1}{T}, \text{ideal gas}
$$<h2 id="isothermal-compressibility">
<a class="header-anchor" href="#isothermal-compressibility"></a>
Isothermal Compressibility $\kappa_T$
</h2>$$
\kappa_T=-\frac{1}{V}(\frac{\partial V}{\partial P})_T=\frac{1}{p}, \text{ideal gas}
$$<h2 id="heat-capacity-c">
<a class="header-anchor" href="#heat-capacity-c"></a>
Heat Capacity C
</h2>$$
C=\lim_{\Delta T \to 0}\frac{\Delta Q}{\Delta T}
$$<h2 id="constant-volume-heat-capacity">
<a class="header-anchor" href="#constant-volume-heat-capacity"></a>
Constant Volume Heat Capacity $C_V$
</h2>$$
C_V=(\frac{\partial U}{\partial T})_V=T(\frac{\partial S}{\partial T})_V
$$<h2 id="heat-capacity-at-constant-pressure">
<a class="header-anchor" href="#heat-capacity-at-constant-pressure"></a>
Heat Capacity at Constant Pressure $C_p$
</h2>$$
C_p=(\frac{\partial H}{\partial T})_p=T(\frac{\partial S}{\partial T})_p
$$<h2 id="multipartite-heat-capacity">
<a class="header-anchor" href="#multipartite-heat-capacity"></a>
Multipartite Heat Capacity $C_n$
</h2>$$
C_n=T(\frac{\partial S}{\partial T})_n
$$<h2 id="adiabatic-equation-for-ideal-gas">
<a class="header-anchor" href="#adiabatic-equation-for-ideal-gas"></a>
Adiabatic Equation for Ideal Gas
</h2><p>$\gamma$：[[#Adiabatic Index]]
C: Constant
</p>
$$
pV^\gamma=C_1
$$<p>
</p>
$$
TV^{\gamma-1}=C_2
$$<p>
</p>
$$
P^{1-\gamma}T^\gamma=C_3
$$<h2 id="the-second-law-of-thermodynamics">
<a class="header-anchor" href="#the-second-law-of-thermodynamics"></a>
==The Second Law of Thermodynamics==
</h2>$$
dS\ge \frac{dQ}{T}
$$<ol>
<li>Two adiabatic lines cannot intersect.</li>
<li>T: External temperature</li>
<li>The external temperature equals the system temperature (T) if and only if the process is reversible.</li>
</ol>
<h2 id="efficiency-of-reversible-heat-engine">
<a class="header-anchor" href="#efficiency-of-reversible-heat-engine"></a>
Efficiency of Reversible Heat Engine $\eta$
</h2><p>[[#Carnot&rsquo;s Theorem]]
</p>
$$
\eta=1-\frac{T_1}{T_2}
$$<ul>
<li>$T_2$: Temperature of the high-temperature heat reservoir</li>
<li>$T_1$: Temperature of the low-temperature heat reservoir</li>
<li>$0<\eta<1$</li>
</ul>
<h2 id="energy-equation-in-throttling-process">
<a class="header-anchor" href="#energy-equation-in-throttling-process"></a>
Energy Equation in Throttling Process
</h2><p>For the throttling process, the following energy balance equation can be written:
</p>
$$
H_1 = H_2
$$<p>where, $H_1$ and $H_2$ are the enthalpies before and after throttling, respectively.
<strong>Proof</strong>:
The system is adiabatic, $\Delta U=W$
$U_2-U_1=p_1V_1-p_2V_2$
$U_2+p_2V_2=U_1+p_1V_1$
$H_2=H_1$</p>
<h2 id="joule-thomson-coefficient">
<a class="header-anchor" href="#joule-thomson-coefficient"></a>
Joule-Thomson Coefficient
</h2><p>[[#Throttling Process]]
</p>
$$
\mu=(\frac{\partial T}{\partial p})_H=\frac{V}{C_p}(T\alpha-1)
$$<h2 id="fundamental-equations-of-thermodynamics-for-open-systems-">
<a class="header-anchor" href="#fundamental-equations-of-thermodynamics-for-open-systems-"></a>
Fundamental Equations of Thermodynamics for Open Systems ($+\mu dn$)
</h2><h1 id="">
<a class="header-anchor" href="#"></a>

</h1><h2 id="total-differential-of-internal-energy">
<a class="header-anchor" href="#total-differential-of-internal-energy"></a>
Total Differential of Internal Energy
</h2>$$
dU=dQ+dW+\mu dn=TdS-pdV+\mu dn
$$<h2 id="enthalpy-total-differential-1">
<a class="header-anchor" href="#enthalpy-total-differential-1"></a>
Enthalpy Total Differential
</h2>$$
dH=dU+d(pV)+\mu dn=TdS+Vdp+\mu dn
$$<h2 id="differential-of-free-energy-1">
<a class="header-anchor" href="#differential-of-free-energy-1"></a>
Differential of Free Energy
</h2>$$
dF=-SdT-pdV+\mu dn
$$<h2 id="gibbs-function-total-differential-1">
<a class="header-anchor" href="#gibbs-function-total-differential-1"></a>
Gibbs Function Total Differential
</h2>$$
dG=-SdT+Vdp+\mu dn
$$<h2 id="grand-potential">
<a class="header-anchor" href="#grand-potential"></a>
Grand Potential
</h2>$$
J=-pV
$$<h2 id="the-clausius-clapeyron-equation">
<a class="header-anchor" href="#the-clausius-clapeyron-equation"></a>
The Clausius-Clapeyron Equation
</h2>$$
\frac{dp}{dT}=\frac{S_m^\beta-S_m^\alpha}{V_m^\beta-V_m^\alpha}=\frac{L}{T(V_m^\beta-V_m^\alpha)}=\frac{s^\beta-s^\alpha}{v^\beta-v^\alpha}
$$<p>
Where:</p>
<ul>
<li>$L=T(S_m^\beta-S_m^\alpha)$ is the latent heat of phase transition.</li>
<li>$S_m$ is the molar entropy</li>
<li>$s$ is the specific entropy (entropy per unit mass)</li>
<li>$v$ is the specific volume (volume per unit mass)</li>
</ul>
<h2 id="ehrenfest-equations">
<a class="header-anchor" href="#ehrenfest-equations"></a>
Ehrenfest Equations
</h2><p>In [[#second-order phase transitions]], the Clapeyron equation becomes an indeterminate form of $\frac{0}{0}$. By applying L&rsquo;Hôpital&rsquo;s rule and taking partial derivatives of the numerator and denominator with respect to $T$, we obtain
</p>
$$
\frac{d𝑝}{d𝑇}=\frac{\Delta c_𝑝}{𝑇𝑣\Delta\alpha}
$$<p>
Alternatively, taking partial derivatives with respect to $𝑝$ yields
</p>
$$
\frac{d𝑝}{d𝑇}=\frac{\Delta\alpha}{\Delta\kappa_T}
$$<p>
These two equations are known as the <strong>Ehrenfest equations</strong>.</p>
<h2 id="first-order-phase-transition-equation">
<a class="header-anchor" href="#first-order-phase-transition-equation"></a>
First-Order Phase Transition Equation
</h2><h2 id="formula">
<a class="header-anchor" href="#formula"></a>
Formula
</h2><p>For first-order phase transitions, at the transition temperature $T_c$, the Gibbs free energy $G$ itself is continuous, but its first derivatives with respect to temperature and pressure exhibit discontinuities:</p>
<ul>
<li>$\left ( \frac{\partial G}{\partial T} \right)_P = -S$</li>
<li>$\left ( \frac{\partial G}{\partial P} \right)_T = V$</li>
</ul>
<p>At the transition point $T_c$, these first derivatives undergo jumps:
</p>
$$
\Delta S = S_2 - S_1 \neq 0
$$<p>
</p>
$$
\Delta V = V_2 - V_1 \neq 0
$$<p>
Here, $S$ represents entropy, $V$ represents volume, and the subscripts 1 and 2 denote the two phases before and after the phase transition.</p>
<h2 id="proof">
<a class="header-anchor" href="#proof"></a>
Proof
</h2><p>The characteristic of a first-order phase transition lies in the <strong>discontinuity</strong> of <strong>certain first-order derivatives of the thermodynamic potential function</strong> at the transition point. Taking entropy as an example:</p>
<ol>
<li><strong>Continuity of Gibbs Free Energy</strong>:
At the transition temperature $T_c$, the Gibbs free energy $G$ is continuous:
$$
   G_1 (T_c, P) = G_2 (T_c, P)
   $$</li>
<li><strong>Discontinuity of Entropy</strong>:
Taking the partial derivative of $G$ with respect to temperature yields the expression for entropy:
$$
   S = -\left ( \frac{\partial G}{\partial T} \right)_P
   $$
At $T_c$, the jump in entropy is:
$$
   \Delta S = S_2 - S_1 = -\left ( \frac{\partial G_2}{\partial T} \right)_P + \left ( \frac{\partial G_1}{\partial T} \right)_P \neq 0
   $$</li>
</ol>
<p>This demonstrates the discontinuity of entropy at the phase transition point.</p>
<h2 id="second-order-phase-transition-equations">
<a class="header-anchor" href="#second-order-phase-transition-equations"></a>
Second-Order Phase Transition Equations
</h2><h2 id="">
<a class="header-anchor" href="#"></a>

</h2><h2 id="formula-1">
<a class="header-anchor" href="#formula-1"></a>
Formula
</h2><p>For second-order phase transitions, at the critical temperature $T_c$, the Gibbs free energy $G$ and its first derivatives (such as entropy and volume) are continuous, but its second derivatives (such as heat capacity, compressibility, and thermal expansion coefficient) are discontinuous:</p>
<ul>
<li>$\left ( \frac{\partial^2 G}{\partial T^2} \right)_P = \frac{\partial S}{\partial T} = \frac{C_P}{T}$</li>
<li>$\left ( \frac{\partial^2 G}{\partial P^2} \right)_T = \frac{\partial V}{\partial P} = -\kappa_T V$</li>
</ul>
<p>At the phase transition point $T_c$, these second derivatives exhibit jumps:
</p>
$$
\Delta C_P = C_{P 2} - C_{P 1} \neq 0
$$<p>
</p>
$$
\Delta \kappa_T = \kappa_{T 2} - \kappa_{T 1} \neq 0
$$<p>
Here, $C_P$ is the constant-pressure heat capacity, and $\kappa_T$ is the isothermal compressibility.</p>
<h2 id="proof-1">
<a class="header-anchor" href="#proof-1"></a>
Proof
</h2><p>The characteristics of second-order phase transitions lie in <strong>the discontinuity of certain second derivatives of the thermodynamic potential function at the phase transition point</strong>. Taking heat capacity as an example:</p>
<ol>
<li><strong>Continuity of Entropy</strong>:
At the phase transition temperature $T_c$, the entropy $S$ is continuous:
$$
   S_1 (T_c, P) = S_2 (T_c, P)
   $$</li>
<li><strong>Discontinuity of Heat Capacity</strong>:
Taking the partial derivative of entropy with respect to temperature yields the expression for heat capacity:
$$
   C_P = T \left ( \frac{\partial S}{\partial T} \right)_P
   $$
At $T_c$, the jump in heat capacity is:
$$
   \Delta C_P = C_{P 2} - C_{P 1} = T \left ( \left ( \frac{\partial S_2}{\partial T} \right)_P - \left ( \frac{\partial S_1}{\partial T} \right)_P \right) \neq 0
   $$</li>
</ol>
<p>This indicates that heat capacity exhibits discontinuity at the phase transition point.</p>
<h2 id="differential-of-the-gibbs-function-for-multicomponent-systems">
<a class="header-anchor" href="#differential-of-the-gibbs-function-for-multicomponent-systems"></a>
Differential of the Gibbs Function for Multicomponent Systems
</h2>$$
dG=-SdT+Vdp+\sum_i\mu_i dn_i
$$<h2 id="gibbs-phase-rule">
<a class="header-anchor" href="#gibbs-phase-rule"></a>
Gibbs Phase Rule
</h2>$$
f=k+2-\varphi
$$<p>
Where:</p>
<ul>
<li>$f$: Degrees of freedom in a multicomponent multiphase system, i.e., the number of independently variable intensive properties</li>
<li>$k$: Number of components</li>
<li>$\varphi$: Number of phases</li>
</ul>
<h2 id="de-broglie-relations">
<a class="header-anchor" href="#de-broglie-relations"></a>
de Broglie Relations
</h2><p>[[#de Broglie Wave]]
</p>
$$
\begin{cases}
\varepsilon=\hbar\omega\\
\vec{p}=\hbar\vec{k}
\end{cases}
$$<h2 id="planck-constant">
<a class="header-anchor" href="#planck-constant"></a>
Planck Constant
</h2>$$
\begin{align}
h & =6.626069934(89)×10^{-34}J\cdot s \\
& =4.135667662(25)×10^{-15}eV\cdot s
\end{align}
$$<p>
Reduced Planck Constant (Dirac Constant):
</p>
$$
\hbar \equiv \frac{h}{2\pi}=1.054571800(13)\times10^{-34}J\cdot s
$$<h2 id="uncertainty-relation">
<a class="header-anchor" href="#uncertainty-relation"></a>
Uncertainty Relation
</h2>$$
\Delta q\Delta p\ge h
$$<p>
<strong>Or</strong>
</p>
$$
\Delta q\Delta p\ge \frac{\hbar}{2}
$$<p>
==Generally==, take
</p>
$$
\Delta q\Delta p\approx h
$$<h2 id="three-dimensional-free-particle-quantum-state-count">
<a class="header-anchor" href="#three-dimensional-free-particle-quantum-state-count"></a>
Three-Dimensional Free Particle Quantum State Count
</h2><p>==Temporarily disregarding quantum spin==</p>
<blockquote>
<p>When particles move within a macroscopically sized container, their momentum and energy values are <strong>quasi-continuous</strong>.</p></blockquote>
<h2 id="cartesian-momentum-representation">
<a class="header-anchor" href="#cartesian-momentum-representation"></a>
Cartesian Momentum Representation
</h2><p>Find the <strong>number of quantum states for free particles</strong> within a volume $V=L^3$, in the momentum range from $p_x$ to $p_x+dp_x$, $p_y$ to $p_y+dp_y$, and $p_z$ to $p_z+dp_z$.<br>
Solution 1:<br>
From the relationship between momentum and quantum numbers for [[#Three-Dimensional Free Particles]], the possible number of $p_x$ states is:<br>
</p>
$$
dn_x=\frac{L}{2\pi\hbar}dp_x
$$<p><br>
This means $dn_x$ is characterized by $dp_x$.<br>
The same applies to the other two directions.<br>
</p>
$$
dn_xdn_ydn_z=\frac{V}{h^3}dp_xdp_ydp_z
$$<p><br>
Solution 2:<br>
From the definition of [[#Phase Cell]], the phase cell size for a three-dimensional free particle is $\Delta q_1\cdots \Delta q_r\Delta p_1\cdots \Delta p_r\approx h^3$. In this problem, the $\mu$-space volume is $d\Omega=Vdp_xdp_ydp_z$.<br>
The number of phase cells that can fit into this volume is the number of quantum states for free particles.<br>
</p>
$$
dn_xdn_ydn_z=\frac{d\Omega}{h^3}=\frac{Vdp_xdp_ydp_z}{h^3}
$$<h2 id="momentum-representation-in-spherical-coordinates">
<a class="header-anchor" href="#momentum-representation-in-spherical-coordinates"></a>
Momentum Representation in Spherical Coordinates
</h2>$$
\displaylines{p_x=p\sin \theta \cos \varphi 
\\p_y=p\sin \theta \sin \varphi 
\\p_z=p\cos \theta}
$$<p>
</p>
$$
dp_xdp_ydp_z=p^2\sin \theta dp d\theta d\varphi
$$<p>
Within volume $V$, for momentum magnitude ranging from $p$ to $p+dp$, direction from $\theta$ to $d\theta$, and $\varphi$ to $\varphi+d\varphi$, the number of possible states for a free particle is
</p>
$$
\frac{Vp^2\sin \theta dp d\theta d\varphi}{h^3}
$$<p>
<em>There are three quantum numbers $p,\theta,\varphi$ in total, corresponding to three degrees of freedom.</em></p>
<h2 id="energy-representation">
<a class="header-anchor" href="#energy-representation"></a>
Energy Representation
</h2><p>Integrating over $\theta,\varphi$ ($0<\theta<\pi,0<\varphi<2\pi$) gives:
</p>
$$
\frac{4\pi Vp^2}{h^3}dp
$$<p>
Here the momentum can be in any direction, with 1 degree of freedom.
$\because$ $\varepsilon=\frac{p^2}{2m}$
$\therefore$ Within volume $V$, the number of possible quantum states for free particles in the energy range from $\varepsilon$ to $\varepsilon+d\varepsilon$ is
</p>
$$
D(\varepsilon)d\varepsilon=\frac{2\pi V}{h^3}(2m)^{3/2}\varepsilon^{1/2}d\varepsilon
$$<p>
where $D(\varepsilon)$ represents the number of possible states per unit energy interval, known as the ==density of states==.</p>
<h2 id="considering-quantum-spin">
<a class="header-anchor" href="#considering-quantum-spin"></a>
Considering Quantum Spin
</h2><p>[[#Spin Angular Momentum]]
Number of quantum states = Number of momentum quantum states obtained above * Possible spin states of the particle
eg. If the particle&rsquo;s spin quantum number is $\frac{1}{2}$, $S_z=2s+1=1$, the above result should be multiplied by 2.</p>
<h1 id="definitions-and-theorems">
<a class="header-anchor" href="#definitions-and-theorems"></a>
Definitions and Theorems
</h1><h2 id="basic-definitions">
<a class="header-anchor" href="#basic-definitions"></a>
Basic Definitions
</h2><h1 id="">
<a class="header-anchor" href="#"></a>

</h1><h2 id="equilibrium-state">
<a class="header-anchor" href="#equilibrium-state"></a>
Equilibrium State
</h2><p>The definition of equilibrium state focuses on two points:</p>
<ol>
<li>There is <strong>no macroscopic</strong> exchange of energy or matter between the system and its surroundings (distinguished from <strong>steady state</strong>). Microscopic exchanges are allowed.</li>
<li>The macroscopic properties of all parts of the system remain unchanged over a long period of time. Equilibrium state is <strong>thermodynamic equilibrium</strong>, with <strong>fluctuations</strong> present.</li>
</ol>
<p><strong>Relaxation time</strong>: The time required for a system to return to equilibrium from a non-equilibrium state.</p>
<h2 id="methods-for-describing-equilibrium-properties-macroscopic-description">
<a class="header-anchor" href="#methods-for-describing-equilibrium-properties-macroscopic-description"></a>
Methods for Describing Equilibrium Properties: Macroscopic Description
</h2><ul>
<li>State parameters: Macroscopic variables that determine equilibrium properties</li>
<li>State functions: Macroscopic variables determined by state parameters</li>
</ul>
<h2 id="extensive-and-intensive-quantities">
<a class="header-anchor" href="#extensive-and-intensive-quantities"></a>
Extensive and Intensive Quantities
</h2><p>In thermodynamics, the <strong>macroscopic variables</strong> of a homogeneous system can be divided into two categories: extensive and intensive quantities.</p>
<h2 id="广延量extensive-variables">
<a class="header-anchor" href="#%e5%b9%bf%e5%bb%b6%e9%87%8fextensive-variables"></a>
广延量（Extensive Variables）
</h2><blockquote>
<p>广延量是指<strong>依赖于系统规模或大小的热力学变量</strong>。这些变量随着系统的大小成比例地增加或减少。</p></blockquote>
<ul>
<li><strong>质量（Mass）</strong>：整个系统的质量。</li>
<li><strong>体积（Volume, V）</strong>：系统占据的空间体积。</li>
<li><strong>能量（Energy, E）</strong>：包括内部能量、动能和势能。</li>
<li><strong>熵（Entropy, S）</strong>：表示系统微观状态的不确定性和混乱度。</li>
<li><strong>粒子数（Number of particles, N）</strong>：系统中粒子的总数。</li>
<li><strong>热量（Heat, Q）</strong>：系统所包含或传递的热量。</li>
<li><strong>电荷（Charge, Q）</strong>：系统中的电荷总量。</li>
</ul>
<h2 id="强度量intensive-variables">
<a class="header-anchor" href="#%e5%bc%ba%e5%ba%a6%e9%87%8fintensive-variables"></a>
强度量（Intensive Variables）
</h2><blockquote>
<p>强度量是指<strong>与系统的大小无关</strong>的热力学变量，这些变量<strong>在系统内的任一点都保持一致</strong>，不随系统规模而变化。</p></blockquote>
<ul>
<li><strong>温度（Temperature, T）</strong>：表示系统的热状态。</li>
<li><strong>压强（Pressure, P）</strong>：系统单位面积上所受的力。</li>
<li><strong>化学势（Chemical potential, μ）</strong>：系统中每增加一个粒子所需要的自由能。</li>
<li><strong>浓度（Concentration）</strong>：单位体积内粒子的数量。</li>
<li><strong>电场（Electric field, E）</strong>：单位电荷所受的力。</li>
<li><strong>磁场（Magnetic field, H）</strong>：单位磁偶极子所受的力矩。</li>
</ul>
<h2 id="the-relationship-between-extensive-and-intensive-quantities">
<a class="header-anchor" href="#the-relationship-between-extensive-and-intensive-quantities"></a>
The Relationship Between Extensive and Intensive Quantities
</h2><p>Extensive and intensive quantities are closely related. Typically, <strong>extensive quantities can be calculated through the product or integral of intensive quantities</strong>. For example:</p>
<ul>
<li><strong>Internal energy</strong> (U): Can be determined by the system&rsquo;s temperature, volume, and particle count.</li>
<li><strong>Volume</strong>: Can be calculated by integrating the density of each unit volume within the system.</li>
<li><strong>Heat and work</strong>: Are the products of intensive quantities (such as temperature and pressure) and extensive quantities (such as entropy and volume change).</li>
</ul>
<h2 id="temperature">
<a class="header-anchor" href="#temperature"></a>
Temperature
</h2><blockquote>
<p><strong>Law of Thermal Equilibrium</strong>: If object A is in thermal equilibrium with objects B and C respectively, then B and C must also be in thermal equilibrium when they are in thermal contact.</p></blockquote>
<ul>
<li>Definition of temperature: Objects in mutual thermal equilibrium must possess a physical quantity intrinsic to the object itself, which is defined as temperature.</li>
<li>Temperature scale: A numerical representation method for temperature.</li>
<li>Three essential elements: Thermometric property of the thermometric substance, fixed points, and scale division.</li>
</ul>
<h2 id="work-in-thermodynamic-processes">
<a class="header-anchor" href="#work-in-thermodynamic-processes"></a>
Work in Thermodynamic Processes
</h2><p><strong>Quasi-static process</strong>: $W=\int_{V_1}^{V_2}pdV$, where $V_1$ is the initial volume of the system and $V_2$ is the final volume.</p>
<p><strong>Reversible process: A quasi-static process without dissipation</strong></p>
<blockquote>
<p>In a reversible process, the work done by the surroundings on the system can be expressed using the system&rsquo;s state parameters.</p></blockquote>
<p><strong>State space: A space constructed with independent state parameters as coordinate axes.</strong></p>
<blockquote>
<p>In state space, a point represents an equilibrium state of the system, and a curve represents a quasi-static process.</p></blockquote>
<p><strong>Process equation: The functional relationship between independent state parameters during a quasi-static process.</strong></p>
<p>Expressions for work (considering only reversible processes):</p>
<ul>
<li>Fluid volume change process: −𝑝d𝑉</li>
<li>Surface film area change process: 𝜎d𝐴</li>
<li>Elastic wire length change: 𝐹d𝐿</li>
<li>Polarization work (ignoring dielectric volume change):</li>
<li>Magnetization work (ignoring magnetic medium volume change):</li>
</ul>
<p><strong>Work in special non-static processes</strong>:</p>
<ul>
<li>Isochoric (constant volume) $𝑊=0$</li>
<li>Isobaric (constant pressure) $𝑊=−𝑝 \Delta 𝑉$</li>
</ul>
<h2 id="carnots-theorem">
<a class="header-anchor" href="#carnots-theorem"></a>
Carnot&rsquo;s Theorem
</h2><p><strong>Among all heat engines operating between two fixed temperatures, reversible heat engines have the highest efficiency.</strong>
Corollary: If two reversible heat engines operate at the same temperatures, their efficiencies are equal.
[[#Reversible Heat Engine Efficiency $ eta$]]</p>
<h2 id="principle-of-entropy-increase">
<a class="header-anchor" href="#principle-of-entropy-increase"></a>
Principle of Entropy Increase
</h2><blockquote>
<p>Under <strong>adiabatic conditions</strong>, processes that decrease entropy are impossible (entropy never decreases).</p></blockquote>
<p><strong>Proof</strong>: From the second law of thermodynamics:
</p>
$$
dS\ge \frac{dQ}{T}
$$<p>
For an adiabatic system, $dQ$=0, thus $dS\ge 0$.</p>
<p><strong>Corollary</strong>: In an isolated (adiabatic) system, <strong>irreversible processes</strong> always proceed in the direction of increasing entropy, i.e., $dS>0$.</p>
<h2 id="throttling-process">
<a class="header-anchor" href="#throttling-process"></a>
Throttling Process
</h2><p>In thermodynamics, the throttling process (or Joule-Thomson process) is a typical adiabatic irreversible process characterized by a significant pressure drop as the fluid passes through a throttling device (such as an orifice, valve, or porous plug), while the enthalpy remains constant. Below is a detailed analysis of this process:</p>
<h2 id="characteristics-of-throttling-process">
<a class="header-anchor" href="#characteristics-of-throttling-process"></a>
Characteristics of Throttling Process
</h2><ol>
<li><strong>Adiabatic Nature</strong>: The throttling process is typically considered adiabatic because there is insufficient time for heat exchange during rapid flow.</li>
<li><strong>Isenthalpic Property</strong>: The most important characteristic is that the throttling process is isenthalpic, meaning the enthalpy ($H$) remains unchanged before and after throttling. This property plays a key role in the throttling process. [[#Energy Equation in Throttling Process]]</li>
<li><strong>Irreversibility</strong>: The throttling process is an <strong>irreversible process</strong>, and the <strong>entropy of the system usually increases</strong>.</li>
<li><strong>Pressure Drop</strong>: During the throttling process, the pressure of the fluid drops significantly.</li>
</ol>
<h2 id="relationship-between-enthalpy-temperature-and-pressure">
<a class="header-anchor" href="#relationship-between-enthalpy-temperature-and-pressure"></a>
Relationship Between Enthalpy, Temperature, and Pressure
</h2><p>For an ideal gas, enthalpy is solely a function of temperature, so the temperature remains constant during a throttling process (a special case of the Joule-Thomson effect). However, for real gases, the situation is more complex—the temperature may increase or decrease depending on the gas&rsquo;s ==Joule-Thomson coefficient== ([[#Joule-Thomson Coefficient]]), defined as:
</p>
$$
\mu_{JT} = \left ( \frac{\partial T}{\partial P} \right)_H
$$<ul>
<li>If $\mu_{JT} > 0$, the gas temperature decreases during throttling.</li>
<li>If $\mu_{JT} < 0$, the gas temperature increases during throttling.</li>
</ul>
<h2 id="applications-of-throttling-process">
<a class="header-anchor" href="#applications-of-throttling-process"></a>
Applications of Throttling Process
</h2><p>The throttling process is crucial in many industrial applications, such as:</p>
<ul>
<li><strong>Refrigeration Systems</strong>: Utilizing throttling valves (e.g., expansion valves) to reduce the temperature and pressure of refrigerants, thereby achieving cooling effects.</li>
<li><strong>Gas Separation</strong>: Cooling certain gases to their liquefaction temperature through throttling to separate different gas components.</li>
</ul>
<h2 id="characteristic-functions">
<a class="header-anchor" href="#characteristic-functions"></a>
Characteristic Functions
</h2><p>Characteristic functions (also known as thermodynamic potential functions or thermodynamic potentials) are used to describe the state of a thermodynamic system. Various thermodynamic properties and relationships can be derived from these functions.<br>
There are four main characteristic functions: internal energy, Helmholtz free energy, enthalpy, and Gibbs free energy.</p>
<ul>
<li>Internal energy $U(S,V)$: For adiabatic isochoric systems, U remains constant</li>
<li>Enthalpy $H(S,p)$: For adiabatic isobaric systems, H remains constant</li>
<li>Free energy $F(T,V)$: For isothermal isochoric systems, F remains constant</li>
<li>Gibbs function $G(T,p)$: For isothermal isobaric systems, G remains constant</li>
</ul>
<h2 id="radiation">
<a class="header-anchor" href="#radiation"></a>
Radiation
</h2><h2 id="equilibrium-radiation">
<a class="header-anchor" href="#equilibrium-radiation"></a>
Equilibrium Radiation
</h2><p>Equilibrium Radiation refers to the electromagnetic radiation characteristics of a system in a state of <strong>thermodynamic equilibrium</strong>. In this state, the processes of radiation and absorption within the system reach a dynamic balance, and the spectrum and intensity of electromagnetic radiation are solely determined by the system&rsquo;s temperature.</p>
<h2 id="characteristics-of-equilibrium-radiation">
<a class="header-anchor" href="#characteristics-of-equilibrium-radiation"></a>
Characteristics of Equilibrium Radiation
</h2><ol>
<li><strong>Thermal Equilibrium</strong>:
<ul>
<li>The system is in a state of thermal equilibrium, meaning the temperature is uniform across all parts, with no net heat flow.</li>
</ul>
</li>
<li><strong>Blackbody Radiation</strong>:
<ul>
<li>Under thermal equilibrium, the radiation exhibits blackbody characteristics. Blackbody radiation is an idealized form of radiation that perfectly absorbs and re-emits all frequencies, with its spectrum depending solely on temperature.</li>
</ul>
</li>
</ol>
<h2 id="radiative-flux-density">
<a class="header-anchor" href="#radiative-flux-density"></a>
Radiative Flux Density
</h2><p>辐射通量密度（Radiative Flux Density），也称为辐射出射度或辐射强度，是指单位时间内通过单位面积的辐射能量。它是描述辐射场的重要物理量，在热力学、气象学、天文学等领域有广泛应用。</p>
<h2 id="definition">
<a class="header-anchor" href="#definition"></a>
Definition
</h2><p>The radiant flux density E is expressed as:
</p>
$$
E = \frac{d\Phi}{dA}
$$<p>
where:</p>
<ul>
<li>E is the radiant flux density, measured in watts per square meter ($W/m^2$).</li>
<li>$d\Phi$ is the radiant energy flux passing through area $dA$, measured in watts ($W$).</li>
<li>$dA$ is the area, measured in square meters ($m^2$).</li>
</ul>
<p>==Or==
</p>
$$
J_u=\frac{c}{4}\frac{U}{V}=\frac{1}{4}cu
$$<p>
where:</p>
<ul>
<li>$c$: speed of light</li>
<li>$u$: radiant energy density, $u=\frac{U}{V}$, the equilibrium radiant energy per unit volume</li>
</ul>
<h2 id="applications-of-the-stefan-boltzmann-law">
<a class="header-anchor" href="#applications-of-the-stefan-boltzmann-law"></a>
Applications of the Stefan-Boltzmann Law
</h2><p>For an ideal black body, its radiant flux density is proportional to the fourth power of its temperature, as described by the Stefan-Boltzmann law:
</p>
$$
E = \sigma T^4
$$<p>
where:</p>
<ul>
<li>$E$ is the radiant flux density of the black body.</li>
<li>$\sigma$ is the Stefan-Boltzmann constant, with a value of $5.67 \times 10^{-8} \, W \, m^{-2} \, K^{-4}$.</li>
<li>$T$ is the absolute temperature of the black body, in Kelvin ($K$).</li>
</ul>
<h2 id="directionality-of-radiant-flux-density">
<a class="header-anchor" href="#directionality-of-radiant-flux-density"></a>
Directionality of Radiant Flux Density
</h2><p>辐射通量密度是一个矢量量，考虑其方向性时称为辐射强度 $I$，表示为单位立体角上的辐射通量密度：
</p>
$$
I = \frac{d\Phi}{dA \cos \theta \, d\Omega}
$$<p>
其中：</p>
<ul>
<li>$I$ 是辐射强度，单位是瓦特每平方米每立体角（$W/m^2/sr$）。</li>
<li>$d\Omega$ 是立体角，单位是球面度（sr）。</li>
<li>$\theta$ 是辐射方向与法线之间的夹角。</li>
</ul>
<h2 id="blackbody-radiation-cavity-radiation">
<a class="header-anchor" href="#blackbody-radiation-cavity-radiation"></a>
Blackbody Radiation (Cavity Radiation)
</h2><p>黑体辐射（Blackbody Radiation）是指一个理想化的物体（称为黑体）在热平衡状态下发出的电磁辐射。黑体是一个理想化的概念，它具有完全吸收和完全辐射所有频率电磁波的能力。黑体辐射的特性只取决于黑体的温度，而与其材料或表面性质无关。</p>
<h2 id="">
<a class="header-anchor" href="#"></a>

</h2><h2 id="characteristics-of-blackbody-radiation">
<a class="header-anchor" href="#characteristics-of-blackbody-radiation"></a>
Characteristics of Blackbody Radiation
</h2><ol>
<li><strong>Perfect Absorption</strong>:
<ul>
<li>A blackbody can completely absorb all incident electromagnetic radiation, regardless of wavelength or direction. Thus, a blackbody exhibits no reflection or transmission at any wavelength.</li>
</ul>
</li>
<li><strong>Perfect Emission</strong>:
<ul>
<li>A blackbody emits electromagnetic radiation at any temperature, radiating across all wavelengths. This radiation is solely determined by the blackbody&rsquo;s temperature.</li>
</ul>
</li>
</ol>
<h2 id="practical-applications-of-blackbody-radiation">
<a class="header-anchor" href="#practical-applications-of-blackbody-radiation"></a>
Practical Applications of Blackbody Radiation
</h2><ol>
<li><strong>Cosmic Background Radiation</strong>:
<ul>
<li>The cosmic microwave background radiation closely approximates blackbody radiation at a temperature of 2.725 K, serving as crucial evidence for the Big Bang theory.</li>
</ul>
</li>
<li><strong>Stellar Spectra</strong>:
<ul>
<li>The radiation from stars approximates blackbody radiation, allowing their surface temperatures to be deduced by analyzing their spectra.</li>
</ul>
</li>
<li><strong>Infrared Thermometry</strong>:
<ul>
<li>Based on the principle of blackbody radiation, the surface temperature of an object can be inferred by measuring the intensity of the infrared radiation it emits.</li>
</ul>
</li>
<li><strong>Thermal Imaging</strong>:
<ul>
<li>Thermal imaging devices utilize the principle of blackbody radiation, detecting infrared radiation emitted from an object&rsquo;s surface to create temperature-based images.</li>
</ul>
</li>
</ol>
<h2 id="criteria-for-thermodynamic-equilibrium">
<a class="header-anchor" href="#criteria-for-thermodynamic-equilibrium"></a>
Criteria for Thermodynamic Equilibrium
</h2><h2 id="isolated-system">
<a class="header-anchor" href="#isolated-system"></a>
Isolated System
</h2><p>For an isolated (adiabatic) system, S increases or remains constant, reaching $S_\max$ at equilibrium.
If a small disturbance occurs, $\Delta S<0$, expand it to a second-order Taylor series $\Delta S=\delta S+\frac{1}{2}\delta^2 S$
At equilibrium, the conditions $\delta S=0,\delta^2 S<0$ must be satisfied.</p>
<h2 id="isothermal-isochoric-system">
<a class="header-anchor" href="#isothermal-isochoric-system"></a>
Isothermal-Isochoric System
</h2><p>等温等容系统 F decreases or remains constant, reaching $F_\min$ at equilibrium.
If a small disturbance occurs, $\Delta F>0$, which can be expanded as a second-order Taylor series $\Delta F=\delta F+\frac{1}{2}\delta^2 F$.
At equilibrium, the conditions $\delta F=0,\delta^2 F>0$ are satisfied.</p>
<h2 id="isothermal-isobaric-system">
<a class="header-anchor" href="#isothermal-isobaric-system"></a>
Isothermal-Isobaric System
</h2><p>In an isothermal-isobaric system, G decreases or remains constant, reaching $G_\min$ at equilibrium.
If a slight perturbation occurs, $\Delta G>0$, which can be expanded as a second-order Taylor series: $\Delta G=\delta G+\frac{1}{2}\delta^2 G$.
At equilibrium, the conditions $\delta G=0$ and $\delta^2 G>0$ must be satisfied.</p>
<h2 id="equilibrium-conditions-for-two-phase-systems-in-a-unit">
<a class="header-anchor" href="#equilibrium-conditions-for-two-phase-systems-in-a-unit"></a>
Equilibrium Conditions for Two-Phase Systems in a Unit
</h2>$$
\begin{cases}  
T^\alpha=T^\beta \\  
p^\alpha=p^\beta \\  
\mu^\alpha=\mu^\beta  
\end{cases}  
$$<h2 id="classification-of-phase-transitions">
<a class="header-anchor" href="#classification-of-phase-transitions"></a>
Classification of Phase Transitions
</h2><p>[[#Ehrenfest Equations]]
Ehrenfest (Paul Ehrenfest) classified phase transitions <strong>based on the continuity of thermodynamic potential functions and their derivatives at the phase transition point</strong>.
Ehrenfest categorized phase transitions into first-order and second-order phase transitions.</p>
<h2 id="first-order-phase-transition">
<a class="header-anchor" href="#first-order-phase-transition"></a>
First-Order Phase Transition
</h2><blockquote>
<p>A first-order phase transition refers to a phase transition where the first derivatives of the thermodynamic potential (such as Gibbs free energy), like entropy and volume, are discontinuous at the transition point.</p></blockquote>
<p>Typical first-order phase transitions include melting, vaporization, and sublimation.
[[#First-Order Phase Transition Equations]]</p>
<h2 id="second-order-phase-transition">
<a class="header-anchor" href="#second-order-phase-transition"></a>
Second-order Phase Transition
</h2><blockquote>
<p>A second-order phase transition refers to a phase transition process where the first derivative of the thermodynamic potential function is continuous at the transition point, but its second derivative exhibits discontinuity.</p></blockquote>
<p>Typical second-order phase transitions include the transition of superconductors and liquid crystal phase transitions.<br>
[[#Second-order Phase Transition Equations]]</p>
<h2 id="multicomponent-system-phase-equilibrium-conditions">
<a class="header-anchor" href="#multicomponent-system-phase-equilibrium-conditions"></a>
Multicomponent System Phase Equilibrium Conditions
</h2><h2 id="equilibrium-conditions-for-isothermal-isobaric-systems">
<a class="header-anchor" href="#equilibrium-conditions-for-isothermal-isobaric-systems"></a>
Equilibrium Conditions for Isothermal-Isobaric Systems
</h2>$$
\begin{cases}
T^\alpha=T^\beta \\
p^\alpha=p^\beta \\
\mu_i^\alpha=\mu_i^\beta
\end{cases}
$$<h2 id="the-same-applies-to-other-systems">
<a class="header-anchor" href="#the-same-applies-to-other-systems"></a>
The same applies to other systems
</h2><h2 id="gibbs-paradox">
<a class="header-anchor" href="#gibbs-paradox"></a>
Gibbs Paradox
</h2><p><strong>Description</strong>: The entropy increases abruptly from $2nR\ln 2$ to 0 when transitioning from two arbitrarily similar gases to the same gas.<br>
<strong>Reason</strong>: Indistinguishability of identical particles.</p>
<h2 id="the-third-law-of-thermodynamics">
<a class="header-anchor" href="#the-third-law-of-thermodynamics"></a>
The Third Law of Thermodynamics
</h2><h2 id="nernsts-theorem">
<a class="header-anchor" href="#nernsts-theorem"></a>
Nernst&rsquo;s Theorem
</h2><p>The change in entropy of a condensed system during an isothermal process approaches zero as the thermodynamic temperature tends to zero.
</p>
$$
\lim_{T \to 0}(\Delta S)_T=0
$$<h2 id="principle-of-the-unattainability-of-absolute-zero">
<a class="header-anchor" href="#principle-of-the-unattainability-of-absolute-zero"></a>
Principle of the Unattainability of Absolute Zero
</h2><p>It is impossible to cool an object to thermodynamic zero through <strong>a finite number of steps</strong>.</p>
<h2 id="corollaries">
<a class="header-anchor" href="#corollaries"></a>
Corollaries
</h2><ol>
<li>$\lim_{T \to 0}C_n=0$ This corollary is proven by Einstein&rsquo;s quantum statistics in the [[#solid]] section.</li>
<li>$\lim_{T \to 0}\alpha=0,\lim_{T \to 0}\beta=0$</li>
<li>At absolute zero, the entropy value can be 0</li>
</ol>
<h2 id="classical-description-of-particle-motion-states">
<a class="header-anchor" href="#classical-description-of-particle-motion-states"></a>
Classical Description of Particle Motion States
</h2><h2 id="space">
<a class="header-anchor" href="#space"></a>
$\mu$ Space
</h2><blockquote>
<p>Describes the mechanical motion state of particles using position and momentum coordinates. The $2r$ variables $q_1,q_2,...,q_r;p_1,p_2,...,p_r$ form a $2r$-dimensional space with Cartesian coordinates, known as $\mu$ space.</p></blockquote>
<p><strong>Degrees of Freedom of a Particle</strong>: The minimum number of coordinates required to determine the spatial position <strong>or</strong> configuration position of a particle.</p>
<h2 id="phase-cell">
<a class="header-anchor" href="#phase-cell"></a>
Phase Cell
</h2><blockquote>
<p>The volume of a particle&rsquo;s motion state in $\mu$ space</p></blockquote>
<p>For a particle with $r$ degrees of freedom, the size of the phase cell is $\Delta q_1\cdots \Delta q_r\Delta p_1\cdots \Delta p_r$
When it satisfies the [[#Uncertainty Relation]] $\Delta q_i\Delta p_i\approx h$, the size of the phase cell $\approx h^r$</p>
<h2 id="free-particle">
<a class="header-anchor" href="#free-particle"></a>
Free Particle
</h2><blockquote>
<p>A free particle is a particle that moves freely without the influence of any force.
In the absence of an external field, molecules of an ideal gas or free electrons in a metal can be approximately regarded as free particles.</p></blockquote>
<p><strong>Momentum of a free particle</strong>: $p_x=m\dot{x}$, the momentum of the particle in the x-axis direction. Here, m is the mass of the particle, and $\dot{x}$ is the velocity of the particle in the x-axis direction (the first derivative of position with respect to time).
<strong>Energy of a free particle</strong>:
</p>
$$
\varepsilon=\frac{1}{2m}\sum_ip_i^2
$$<h2 id="linear-harmonic-oscillator">
<a class="header-anchor" href="#linear-harmonic-oscillator"></a>
Linear Harmonic Oscillator
</h2><blockquote>
<p>Classical mechanics tells us that a particle with mass $m$ under the action of an elastic force $F = -Ax$ will perform simple harmonic motion along the $x$-axis near the origin, known as a linear harmonic oscillator.</p></blockquote>
<ul>
<li>Angular frequency of oscillation: $$\omega=\sqrt{\frac{A}{m}}$$</li>
<li>$A$: Elastic coefficient</li>
</ul>
<h2 id="energy-of-a-linear-harmonic-oscillator-with-one-degree-of-freedom">
<a class="header-anchor" href="#energy-of-a-linear-harmonic-oscillator-with-one-degree-of-freedom"></a>
Energy of a Linear Harmonic Oscillator with One Degree of Freedom
</h2><p>The sum of kinetic and potential energy
</p>
$$
\varepsilon=\frac{p^2}{2m}+\frac{A}{2}x^2=\frac{p^2}{2m}+\frac{1}{2}m\omega^2x^2
$$<p>
Written in the standard form of an ellipse equation
</p>
$$
\frac{p^2}{2m\varepsilon}+\frac{x^2}{\frac{2\varepsilon}{m\omega^2}}=1
$$<h2 id="rotor-degree-of-freedom-2">
<a class="header-anchor" href="#rotor-degree-of-freedom-2"></a>
Rotor (Degree of Freedom: 2)
</h2><blockquote>
<p>Consider the motion of a particle \( P \) with mass \( m \) attached to the origin \( O \) by a light rod of fixed length.</p></blockquote>
<ul>
<li>In Cartesian coordinates, the position of the particle is determined by coordinates \( x, y, z \).</li>
</ul>
<p>Particle energy (kinetic energy):
</p>
$$
\varepsilon=\frac{1}{2}m(\dot{x}^2+\dot{y}^2+\dot{z}^2)
$$<ul>
<li>Using spherical coordinates \( r, \theta, \varphi \) to describe the particle&rsquo;s position: \( x = r\sin \theta \cos \varphi, y = r\sin \theta \sin \varphi, z = r\cos \theta \)</li>
</ul>
<p>Particle energy:
</p>
$$
\begin{align}
\varepsilon &=\frac{1}{2}m(\dot{r}^2+r^2\dot{\theta}^2+r^2\sin^2\theta\dot{\varphi}^2)\\
&=\frac{1}{2}m(r^2\dot{\theta}^2+r^2\sin^2\dot{\varphi}^2)
\end{align}
$$<ul>
<li>Introducing conjugate momenta \( p_\theta = mr^2\dot{\theta}, p_\varphi = mr^2\sin^2\theta \dot{\varphi} \), and the moment of inertia \( I \) of the particle relative to \( O \).</li>
<li>\( 0 < \theta < \pi, 0 < \varphi < 2\pi \), two degrees of freedom.</li>
</ul>
$$
\varepsilon=\frac{1}{2I}(p_\theta^2+\frac{1}{\sin^2\theta}p_\varphi^2)
$$<h2 id="diatomic-molecules">
<a class="header-anchor" href="#diatomic-molecules"></a>
Diatomic Molecules
</h2><blockquote>
<p>The two-body problem can be reduced to a single-body problem. In statistical physics, the rotation of a diatomic molecule about its center of mass is treated as a rotor.</p></blockquote>
<p>According to classical mechanics, in the absence of external forces, the total angular momentum of the rotor $\vec L=\vec r\times \vec p$ is a conserved quantity, meaning neither its magnitude nor direction changes over time. Since $\vec r$ is perpendicular to $\vec L$, the motion of the particle lies in a plane perpendicular to $\vec L$. If we choose the $z$-axis to be parallel to $\vec L$, the particle&rsquo;s motion must lie within the $xy$-plane. This is equivalent to fixing $\theta=\frac{\pi}{2}, p_\theta=0$.</p>
<p>The particle&rsquo;s energy in this case is:
</p>
$$
\varepsilon=\frac{p_\varphi^2}{2I}=\frac{L^2}{2I}
$$<p>
where: $L^2=\vec{L}\cdot \vec{L}$<br>
<strong>Here, the particle has 1 degree of freedom</strong>, namely $\varphi$.</p>
<h2 id="quantum-description-of-particle-motion-states">
<a class="header-anchor" href="#quantum-description-of-particle-motion-states"></a>
Quantum Description of Particle Motion States
</h2><h2 id="de-broglie-wave">
<a class="header-anchor" href="#de-broglie-wave"></a>
de Broglie Wave
</h2><blockquote>
<p>Microscopic particles (photons, electrons, protons, neutrons, and even atoms, molecules, etc.) universally exhibit wave-particle duality.
A free particle with energy $\varepsilon$ and momentum $\vec{p}$ is associated with a plane wave of circular frequency $\omega$ and wave vector $\vec{k}$, known as the de Broglie wave.</p></blockquote>
<p>[[#de Broglie Relations]]</p>
<h2 id="quantum-state">
<a class="header-anchor" href="#quantum-state"></a>
Quantum State
</h2><blockquote>
<p>In quantum mechanics, the motion state of microscopic particles is called the quantum state.
The quantum state is characterized by a set of quantum numbers, and the <strong>number of quantum numbers</strong> is equal to the degrees of freedom of the particle.</p></blockquote>
<h1 id="">
<a class="header-anchor" href="#"></a>

</h1><h2 id="linear-harmonic-oscillator-energy">
<a class="header-anchor" href="#linear-harmonic-oscillator-energy"></a>
==Linear Harmonic Oscillator Energy==
</h2><p>[[#Energy of a Linear Harmonic Oscillator with 1 Degree of Freedom]]
In ==quantum physics==, the possible energy values of a linear harmonic oscillator with angular frequency $\omega$ are:
</p>
$$
\varepsilon_n=\hbar\omega(n+\frac{1}{2}),n=0,1,2,\cdots
$$<p>
Here, n is the quantum number representing the oscillator&rsquo;s motion state and energy, with only one such number—meaning the linear harmonic oscillator has 1 degree of freedom.
Clearly, the values of $\varepsilon_n$ are <strong>discrete</strong>.</p>
<h2 id="energy-levels">
<a class="header-anchor" href="#energy-levels"></a>
Energy Levels
</h2><blockquote>
<p>Discrete energies are called energy levels.</p></blockquote>
<p>In $\mu$ space, surfaces with equal energy are called ==equipotential surfaces==. Since these surfaces are discontinuous, each equipotential surface is referred to as an <strong>energy level</strong>.
[[#$ mu$ space]]</p>
<h2 id="rotor-energy">
<a class="header-anchor" href="#rotor-energy"></a>
Rotor Energy
</h2><p>[[#Diatomic Molecule]]
In quantum physics, the value of $L^2$ can only take discrete values:
</p>
$$
L^2=l(l_1)\hbar^2,l=0,1,2,\cdots
$$<p>
For a given angular momentum $L$, its projection $L_z$ along its eigen-direction (taken as the $z$-axis) can only take discrete values:
</p>
$$
L_z=m_l\hbar,m_l=-l,-l+1,\cdots,l
$$<p>
Clearly, there are $2l+1$ possible values for $m_l$.</p>
<blockquote>
<p>A rotor&rsquo;s motion state with <strong>2 degrees of freedom</strong> is characterized by <strong>two quantum numbers</strong> $l,m_l$.
In classical theory, the spatial orientation of the motion plane is arbitrary, whereas in quantum theory, $m_l$ can only take the above discrete values, known as <strong>spatial quantization</strong>.</p></blockquote>
<p>Thus, the rotor&rsquo;s energy is also quantized:
</p>
$$
\varepsilon_l=\frac{l(l+1)\hbar^2}{2I},l=0,1,2,\cdots
$$<h2 id="degeneracy">
<a class="header-anchor" href="#degeneracy"></a>
Degeneracy $\omega_l$
</h2><p>$\because$ It is observed that: the energy depends only on the quantum number $l$, and the quantum state depends on the two quantum numbers $m_l, l$.
$\therefore$ There are $2l+1$ quantum states for the energy level $\varepsilon_l$.</p>
<blockquote>
<p>Generally speaking, if a given energy level has more than one quantum state, it is called degenerate.
If an energy level has only one quantum state, it is called non-degenerate.
If an energy level has k quantum states, its degeneracy is k.</p></blockquote>
<p>Between two adjacent [[#Energy Levels]], there are several [[#Phase Cells]], and the number of phase cells is the <strong>degeneracy</strong> of the energy level.</p>
<h2 id="spin-angular-momentum">
<a class="header-anchor" href="#spin-angular-momentum"></a>
Spin Angular Momentum
</h2><blockquote>
<p>Certain fundamental particles possess intrinsic angular momentum, known as spin angular momentum $S$.</p></blockquote>
$$
S^2=s(s+1)\hbar^2
$$<p>
$s$: ==Spin quantum number==. Can be integer or half-integer, an inherent property of particles that can be summed. [[#Bosons and Fermions]]
The state of spin angular momentum is determined by its magnitude (spin quantum number $s$) and its projection along its <strong>eigenaxis</strong>. Using $z$ to denote the eigenaxis, the possible values of $S_z$ are
</p>
$$
S_z=m_s\hbar,m_s=s,s-1,\cdots,-s
$$<p>
totaling $2s+1$ values.</p>
<h2 id="energy-of-free-particles">
<a class="header-anchor" href="#energy-of-free-particles"></a>
Energy of Free Particles
</h2><h2 id="">
<a class="header-anchor" href="#"></a>

</h2><h2 id="boundary-conditions">
<a class="header-anchor" href="#boundary-conditions"></a>
Boundary Conditions
</h2><blockquote>
<p>To determine the possible states of motion of a particle, it is necessary to know the boundary conditions of the de Broglie wave at the container walls.
Typically, standing wave conditions or periodic boundary conditions are employed.</p></blockquote>
<p>For a <strong>one-dimensional</strong> free particle in a container of length $L$, the periodic boundary condition requires that the possible states of motion must satisfy that an integer multiple of the de Broglie wavelength $\lambda$ equals the container length $L$. That is,
</p>
$$
L=\left\vert n_x \right\vert\lambda,\left\vert n_x \right\vert=0,1,2,\cdots
$$<ul>
<li>$n_x$: The projection of the quantum number $n$ in the $x$-direction. For a one-dimensional free particle, the quantum number is simply $n_x$.</li>
</ul>
<h2 id="one-dimensional-free-particle">
<a class="header-anchor" href="#one-dimensional-free-particle"></a>
One-Dimensional Free Particle
</h2><ul>
<li>Wave vector $k_x$:
$$
k_x=\frac{2\pi}{L}n_x,n_x=0,\pm 1,\pm 2,\cdots
$$</li>
<li>Momentum $p_x$:
$$
p_x=\frac{2\pi\hbar}{L}n_x,n_x=0,\pm 1,\pm 2,\cdots
$$</li>
<li>Energy $\varepsilon_{n_x}$
$$
\varepsilon_{n_x}=\frac{p_x^2}{2m}=\frac{2\pi^2\hbar^2}{m}\cdot\frac{n_x^2}{L^2},n_x=0,\pm 1,\pm 2,\cdots
$$</li>
</ul>
<h2 id="three-dimensional-free-particle">
<a class="header-anchor" href="#three-dimensional-free-particle"></a>
Three-Dimensional Free Particle
</h2><ul>
<li>Momentum:
$$
\begin{cases}
p_x=\frac{2\pi\hbar}{L}n_x,n_x=0,\pm 1,\pm 2,\cdots\\
p_y=\frac{2\pi\hbar}{L}n_y,n_y=0,\pm 1,\pm 2,\cdots\\
p_z=\frac{2\pi\hbar}{L}n_z,n_z=0,\pm 1,\pm 2,\cdots
\end{cases}
$$</li>
<li>Energy:
$$
\varepsilon=\frac{1}{2m}(p_x^2+p_y^2+p_z^2)=\frac{2\pi^2\hbar^2}{m}\frac{n_x^2+n_y^2+n_z^2}{L^2}
$$</li>
<li>Quantum numbers: $n_x,n_y,n_z$ (three in total, corresponding to three degrees of freedom)</li>
<li>Energy levels: Determined by $n_x^2+n_y^2+n_z^2$</li>
</ul>
<h2 id="description-of-the-microscopic-motion-states-of-a-system">
<a class="header-anchor" href="#description-of-the-microscopic-motion-states-of-a-system"></a>
Description of the Microscopic Motion States of a System
</h2><h2 id="microstates">
<a class="header-anchor" href="#microstates"></a>
Microstates
</h2><blockquote>
<p>The microscopic state of a system is its mechanical motion state.<br>
It manifests as different occupation patterns where particles occupy different energy levels and phase cells.</p></blockquote>
<h2 id="system">
<a class="header-anchor" href="#system"></a>
System
</h2><p>==Limited to systems composed of identical and nearly independent particles==</p>
<ul>
<li><strong>System composed of identical particles</strong>: A system consisting of the same type of particles with identical intrinsic properties (same mass, charge, spin, etc.).
Examples include a free electron gas composed of free electrons, helium gas composed of $^4He$ atoms, etc. ^f1b50b</li>
<li><strong>System composed of nearly independent particles</strong>: The interaction between particles is very weak, and the average energy of interaction is much smaller than the average energy of a single particle, so the interaction between particles can be ignored, and the total energy of the system can be expressed as the sum of the energies of individual particles.
Examples include systems composed of ideal gases. ^24ebad
$$
E=\sum^{N}_{i=1}\varepsilon_i
$$
Where:</li>
<li>$\varepsilon_i$: Energy of the i-th particle</li>
<li>$N$: Total number of particles</li>
</ul>
<h2 id="classical-mechanics-description">
<a class="header-anchor" href="#classical-mechanics-description"></a>
Classical Mechanics Description
</h2><blockquote>
<p>In classical physics, identical particles [[#^f1b50b]] are distinguishable.
Determining the microscopic state of motion of a system requires determining the mechanical state of motion (individual quantum state) of each particle.</p></blockquote>
<p>Number of variables: $2Nr$<br>
$r$: degrees of freedom of a single particle</p>
<h2 id="bosons-and-fermions">
<a class="header-anchor" href="#bosons-and-fermions"></a>
Bosons and Fermions
</h2><blockquote>
<p>In nature, microscopic particles can be divided into two categories, known as bosons and fermions.</p></blockquote>
<p>[[#Spin Angular Momentum]]</p>
<h2 id="">
<a class="header-anchor" href="#"></a>

</h2><h2 id="fermion">
<a class="header-anchor" href="#fermion"></a>
Fermion
</h2><blockquote>
<p>Spin quantum number is a half-integer</p></blockquote>
<p>Examples: electron, proton, neutron, $\mu$ meson (all with $\frac{1}{2}$ spin); $^2H$ atom, $^3H$ nucleus (with $\frac{3}{2}$ spin), etc.</p>
<h2 id="boson">
<a class="header-anchor" href="#boson"></a>
Boson
</h2><blockquote>
<p>Spin quantum number is an integer</p></blockquote>
<p>Examples: photon (1), $\pi$ meson (0), $^1H$ atom (1), $^4He$ atom (4), etc.</p>
<h2 id="pauli-exclusion-principle">
<a class="header-anchor" href="#pauli-exclusion-principle"></a>
Pauli Exclusion Principle
</h2><blockquote>
<p>In a system containing multiple identical and nearly independent fermions, an individual quantum state can accommodate at most one fermion.</p></blockquote>
<h2 id="distribution">
<a class="header-anchor" href="#distribution"></a>
Distribution
</h2><blockquote>
<p>A set composed of the number of particles at each <strong>energy level</strong>, this set is called a distribution.</p></blockquote>
$$
\{a_l\}=a_1,a_2,\cdots,a_l,\cdots
$$<p>
$a_l$: The number of particles at energy level $\varepsilon_l$
Satisfies:
</p>
$$
\sum_la_l=N,\sum_la_l\varepsilon_l=E
$$<p>
A distribution encompasses a large number of possible microstates, and a microstate corresponds to a distribution.</p>
<h2 id="three-systems">
<a class="header-anchor" href="#three-systems"></a>
Three Systems
</h2><h2 id="">
<a class="header-anchor" href="#"></a>

</h2><h2 id="boltzmann-system">
<a class="header-anchor" href="#boltzmann-system"></a>
Boltzmann System
</h2><p>A system composed of <strong>identical</strong> [[#^f1b50b]]<strong>nearly independent particles</strong>[[#^24ebad]] that are ==distinguishable==, with <strong>no restriction on the number of particles</strong> occupying a single quantum state, is called a Boltzmann system.</p>
<h2 id="bose-system">
<a class="header-anchor" href="#bose-system"></a>
Bose System
</h2><p>A system composed of bosons, not constrained by the Pauli exclusion principle.
In a Bose system consisting of multiple <strong>identical and nearly independent</strong> bosons, <strong>the number of bosons occupying the same individual quantum state</strong> is unrestricted.</p>
<h2 id="fermi-system">
<a class="header-anchor" href="#fermi-system"></a>
Fermi System
</h2><p>A system composed of fermions, obeying the Pauli exclusion principle.</p>
<h2 id="three-types-of-statistics">
<a class="header-anchor" href="#three-types-of-statistics"></a>
Three Types of Statistics
</h2><h2 id="">
<a class="header-anchor" href="#"></a>

</h2><h2 id="boltzmann-statistics-classical-statistics">
<a class="header-anchor" href="#boltzmann-statistics-classical-statistics"></a>
Boltzmann Statistics (Classical Statistics)
</h2><p>Distinguishable identical particles, with no restriction on the number of particles per phase cell.</p>
<h2 id="bose-statistics">
<a class="header-anchor" href="#bose-statistics"></a>
Bose Statistics
</h2><p>Indistinguishable identical particles, with no restriction on the number of particles per phase cell.</p>
<h2 id="fermi-statistics">
<a class="header-anchor" href="#fermi-statistics"></a>
Fermi Statistics
</h2><p>Indistinguishable identical particles, with a maximum of one particle per phase cell.</p>
<h2 id="principle-of-equal-probability">
<a class="header-anchor" href="#principle-of-equal-probability"></a>
Principle of Equal Probability
</h2><blockquote>
<p>For an <strong>isolated</strong> system in <strong>equilibrium</strong>, all possible microstates of the system are equally probable.</p></blockquote>
<h2 id="most-probable-distribution">
<a class="header-anchor" href="#most-probable-distribution"></a>
Most Probable Distribution
</h2><blockquote>
<p>According to the principle of equal a priori probabilities, for an isolated system in equilibrium, the distribution with the greatest number of microscopic states has the highest probability of occurrence, known as the most probable distribution.</p></blockquote>
<h2 id="boltzmann-distribution">
<a class="header-anchor" href="#boltzmann-distribution"></a>
Boltzmann Distribution
</h2><blockquote>
<p>The most probable distribution of particles in a Boltzmann system is called the <strong>Maxwell-Boltzmann distribution</strong>, or simply the Boltzmann distribution.</p></blockquote>
<ul>
<li>Approximate equation: $\ln m!=m (\ln m-1),m\gg 1$</li>
<li>Denote $\Omega_{m.B.}$ as $\Omega$<br>
Under Boltzmann statistics, this distribution contains the most microstates, with the maximum number of microstates $\Omega$.<br>
$$
a_l=\omega_le^{-\alpha-\beta\varepsilon_l}=e^{-\alpha-\beta\varepsilon_l}\frac{\Delta\omega_l}{h_0^r}
$$<br>
The latter is the ==classical expression of the Boltzmann distribution==.<br>
$$
N=\sum_la_l=\sum_l\omega_le^{-\alpha-\beta\varepsilon_l}=\sum_se^{-\alpha-\beta\varepsilon_s}
$$<br>
$$
E=\sum_l\varepsilon_la_l=\sum_l\omega_l\varepsilon_le^{-\alpha-\beta\varepsilon_l}=\sum_s\varepsilon_se^{-\alpha-\beta\varepsilon_s}
$$<br>
$$
f_s=\frac{a_l}{\omega_l}=e^{-\alpha-\beta\varepsilon_l}
$$</li>
<li>$a_l$: The most probable number of particles (average number of particles) at energy level $\varepsilon_l$, which should satisfy the condition $a_l\gg 1$.</li>
<li>$\alpha$: Lagrange multiplier.</li>
<li>$\beta$: Lagrange multiplier, generally determined by experimental conditions.</li>
<li>$\omega_l$: The number of quantum states at energy level $\varepsilon_l$, i.e., the degeneracy. Should satisfy the condition $\omega_l\gg 1$.</li>
<li>$s$: A quantum state at energy level $\varepsilon_l$.</li>
<li>$\sum_l$: Sum over quantum number $l$.</li>
<li>$\sum_s$: Sum over all quantum states.</li>
<li>$f_s$: The average number of particles in quantum state $s$.</li>
</ul>
<h2 id="bose-distribution">
<a class="header-anchor" href="#bose-distribution"></a>
Bose Distribution
</h2><blockquote>
<p>The most probable distribution of particles in a Bose system is called the Bose-Einstein distribution, abbreviated as the Bose distribution.</p></blockquote>
$$
a_l=\frac{\omega_l}{e^{\alpha+\beta\varepsilon_l}-1}
$$<p>
</p>
$$
N=\sum_la_l=\sum_l\frac{\omega_l}{e^{\alpha+\beta\varepsilon_l}-1}
$$<p>
</p>
$$
E=\sum_l\varepsilon_la_l=\sum_l\frac{\varepsilon_l\omega_l}{e^{\alpha+\beta\varepsilon_l}-1}
$$<p>
</p>
$$
F_s=\frac{a_l}{\omega_l}=\frac{1}{e^{\alpha+\beta\varepsilon_l}-1}
$$<h2 id="fermi-distribution">
<a class="header-anchor" href="#fermi-distribution"></a>
Fermi Distribution
</h2><blockquote>
<p>The most probable distribution of a Fermi system.</p></blockquote>
$$
a_l=\frac{\omega_l}{e^{\alpha+\beta\varepsilon_l}+1}
$$<p>
</p>
$$
N=\sum_la_l=\sum_l\frac{\omega_l}{e^{\alpha+\beta\varepsilon_l}+1}
$$<p>
</p>
$$
E=\sum_l\varepsilon_la_l=\sum_l\frac{\varepsilon_l\omega_l}{e^{\alpha+\beta\varepsilon_l}+1}
$$<p>
</p>
$$
F_s=\frac{a_l}{\omega_l}=\frac{1}{e^{\alpha+\beta\varepsilon_l}+1}
$$<h2 id="relationship-among-the-three-distributions">
<a class="header-anchor" href="#relationship-among-the-three-distributions"></a>
Relationship Among the Three Distributions
</h2><p>If $\alpha$ satisfies the condition ([[#Classical Limit Condition]], non-degeneracy condition)
</p>
$$
e^\alpha \gg 1
$$<p>
then the $\pm$ in the Bose and Fermi distributions can be neglected, and both distributions transition to the Boltzmann distribution.
In this case, for all $l$, we have
</p>
$$
\frac{a_l}{\omega_l}\ll 1
$$<p>
</p>
$$
\Omega_{B.E.}\approx\frac{\Omega_{M.B.}}{N!}\approx\Omega_{F.D.}
$$<h2 id="localization">
<a class="header-anchor" href="#localization"></a>
Localization
</h2><ul>
<li>In nature, some systems can be considered as composed of localized particles.
For example, atoms or ions in a crystal oscillate slightly around their equilibrium positions.</li>
<li>Although these particles are <strong>indistinguishable by their quantum nature</strong>, they can be distinguished based on their positions, so ==localized particles== can be treated as distinguishable particles.</li>
<li>Systems composed of localized particles are called <em>localized systems</em>.
Examples include paramagnetic solids and nuclear spin systems.</li>
</ul>
<blockquote>
<p>Localized systems and Bose (Fermi) systems that satisfy classical limit conditions both obey the Boltzmann distribution.
However, their microscopic state numbers are different.</p></blockquote>
<h2 id="statistical-expressions-of-thermodynamic-quantities">
<a class="header-anchor" href="#statistical-expressions-of-thermodynamic-quantities"></a>
Statistical Expressions of Thermodynamic Quantities
</h2><h1 id="">
<a class="header-anchor" href="#"></a>

</h1><h2 id="internal-energy">
<a class="header-anchor" href="#internal-energy"></a>
Internal Energy
</h2>$$
U=\sum_la_l\varepsilon_l=\sum_l\varepsilon_l\omega_le^{-\alpha-\beta\varepsilon_l}
$$<h2 id="particle-partition-function">
<a class="header-anchor" href="#particle-partition-function"></a>
Particle Partition Function
</h2><p>Abbreviated as partition function
</p>
$$
Z_1=\sum_l\omega_le^{-\beta\varepsilon_l}=\sum_se^{-\beta\varepsilon_s}
$$<p>
<strong>Applicable scope: Nearly independent particle system, particles are distinguishable, and the number of particles each phase cell (quantum state) can accommodate is not limited.</strong></p>
$$
N=e^{-\alpha}\sum_l\omega_le^{-\beta\varepsilon_l}=e^{-\alpha}Z_1
$$<p>By eliminating $\alpha$ from the above three equations, we obtain the ==statistical expression of internal energy==:
</p>
$$
U=-N\frac{\partial}{\partial\beta}\ln Z_1
$$<h2 id="total-differential-of-internal-energy-1">
<a class="header-anchor" href="#total-differential-of-internal-energy-1"></a>
Total Differential of Internal Energy
</h2>$$
dU=\sum_la_ld\varepsilon_l+\sum_l\varepsilon_lda_l
$$<ul>
<li>$\sum_la_ld\varepsilon_l$: The change in internal energy caused by the alteration of energy levels due to changes in external parameters while the particle distribution remains unchanged, which represents <strong>the work done by the surroundings on the system</strong> during the process.</li>
<li>$\sum_l\varepsilon_lda_l$: The change in internal energy caused by the redistribution of particles while the energy levels remain unchanged, which represents <strong>the heat absorbed by the system from the surroundings</strong> during the process.</li>
<li>In an infinitesimal quasi-static process, the heat absorbed by the system from the surroundings equals the increase in internal energy due to <strong>the redistribution of particles among energy levels</strong>.
Clearly, heat has no microscopic counterpart and is a unique <strong>macroscopic quantity</strong> in thermal phenomena.
$dQ$ is not a total differential but merely an <strong>infinitesimal quantity</strong>.</li>
</ul>
<h2 id="entropy">
<a class="header-anchor" href="#entropy"></a>
Entropy
</h2>$$
dS=\frac{1}{T}dQ=\frac{1}{T}(dU-Ydy)
$$<p>
</p>
$$
\beta(dU-Ydy)=Nd(\ln Z_1-\beta\frac{\partial}{\partial\beta}\ln Z_1)
$$<p>
$\beta$ is a function of temperature, let
</p>
$$
\beta=\frac{1}{kT}
$$<p>
</p>
$$
k=R/N_A
$$<ul>
<li>$k$: Boltzmann constant, $k=1.381\times10^{-23}J\cdot K^{-1}$</li>
<li>$N_A$: Avogadro&rsquo;s number, $N_A=6.022\times10^{23}mol^{-1}$</li>
<li>$R$: Molar gas constant, $R=8.314J\cdot K^{-1}\cdot mol^{-1}$</li>
</ul>
$$
dS=Nkd(\ln Z_1-\beta\frac{\partial}{\partial \beta}\ln Z_1)
$$<p>
Integrating gives:
</p>
$$
S=Nk(\ln Z_1-\beta\frac{\partial}{\partial \beta}\ln Z_1)
$$<p>
The integration constant is chosen to be 0.</p>
$$
\ln Z_1=\ln N+\alpha
$$<p>
From the Boltzmann distribution
</p>
$$
a_l=\omega_le^{-\alpha-\beta\varepsilon_l}
$$<p>
we obtain
</p>
$$
\alpha+\beta\varepsilon_l=\ln\frac{\omega_l}{\alpha_l}
$$<p>
Simplifying the entropy gives
</p>
$$
\begin{align}
S&=k(N\ln N+\sum_l(\alpha+\beta\varepsilon_l)a_l)\\
&=k(N\ln N+\sum_la_l\ln \omega_l-\sum_la_l\ln a_l)\\
&=k\ln \Omega
\end{align}
$$<h2 id="boltzmann-relation">
<a class="header-anchor" href="#boltzmann-relation"></a>
Boltzmann Relation
</h2>$$
S=k\ln \Omega
$$<blockquote>
<p>The more microstates a macrostate corresponds to, the greater its disorder and the larger its entropy.</p></blockquote>
<ul>
<li>For distinguishable particle systems (localized systems), $\Omega=\Omega_{M.B.}$</li>
<li>For Bose (Fermi) systems satisfying the classical limit condition, $\Omega=\frac{\Omega_{M.B.}}{N!}$</li>
</ul>
<h2 id="free-energy">
<a class="header-anchor" href="#free-energy"></a>
Free Energy
</h2>$$
F=
\begin{cases}
-NkT\ln Z_1, \text{localized system}\\
-NkT\ln Z_1+kT\ln N!, \text{Bose/Fermi systems satisfying classical limit conditions}
\end{cases}
$$<h2 id="equation-of-state-for-ideal-gas">
<a class="header-anchor" href="#equation-of-state-for-ideal-gas"></a>
Equation of State for Ideal Gas
</h2>$$
p=\frac{N}{\beta}\frac{\partial}{\partial V}\ln Z_1=\frac{NkT}{V}
$$<h2 id="classical-limit-conditions">
<a class="header-anchor" href="#classical-limit-conditions"></a>
Classical Limit Conditions
</h2><p>[[#Three Distribution Relations]]
</p>
$$
e^\alpha=\frac{Z_1}{N}=\frac{V}{N}(\frac{2\pi mkT}{h^2})^{\frac{3}{2}}\gg 1
$$<ol>
<li>The smaller $N/V$, the more rarefied the gas;</li>
<li>The higher the temperature $T$;</li>
<li>The larger the molecular mass $m$
The easier it is to satisfy the classical limit conditions.
Another expression:
$$
n\lambda^3=e^{-\alpha}\ll 1
$$</li>
</ol>
<h2 id="maxwells-velocity-distribution-law">
<a class="header-anchor" href="#maxwells-velocity-distribution-law"></a>
Maxwell&rsquo;s Velocity Distribution Law
</h2><p>Under general conditions, <strong>gases satisfy the classical limit condition</strong>.</p>
<blockquote>
<p>Based on the <strong>Boltzmann distribution</strong>, the translational motion of the center of mass of gas molecules is studied, and the velocity distribution law of gas molecules is derived.</p></blockquote>
<h2 id="maxwell-velocity-distribution-law">
<a class="header-anchor" href="#maxwell-velocity-distribution-law"></a>
Maxwell Velocity Distribution Law
</h2>$$
f(v_x,x_y,x_z)dv_xdv_ydv_z=n(\frac{m}{2\pi kT})^{3/2}e^{-\frac{m}{2kT}(v_x^2+v_y^2+v_z^2)}dv_xdv_ydv_z
$$<p>
$f(v_x,x_y,x_z)$ should satisfy
</p>
$$
f(v_x,x_y,x_z)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}f(v_x,x_y,x_z)dv_xdv_ydv_z=n
$$<p>
$n=\frac{N}{V}$: number of molecules per unit volume</p>
<h2 id="maxwells-speed-distribution-law">
<a class="header-anchor" href="#maxwells-speed-distribution-law"></a>
Maxwell&rsquo;s Speed Distribution Law
</h2><p>Using the <strong>spherical polar coordinates</strong> volume element $v^2\sin \theta dv d \theta d \varphi$ to replace the Cartesian volume element $dv_xdv_ydv_z$, integrating over $\theta,\varphi$ gives the number of molecules per unit volume with speeds in the range $dv$ as:
</p>
$$
f(v)dv=4\pi n(\frac{m}{2\pi kT})^{3/2}e^{-\frac{m}{2kT}v^2}v^2dv
$$<p>
This equation is called the molecular speed distribution of gases.
</p>
$$
f(v)=4\pi n(\frac{m}{2\pi kT})^{3/2}\int_{0}^{\infty}e^{-\frac{m}{2kT}v^2}v^2dv=n
$$<h2 id="most-probable-speed">
<a class="header-anchor" href="#most-probable-speed"></a>
Most Probable Speed $v_p$
</h2><blockquote>
<p>The speed distribution function has a maximum value. The speed at which the speed distribution function reaches its maximum is called the most probable speed.
If the speed is divided into equal intervals, the interval containing $v_p$ has the highest number of molecules.</p></blockquote>
$$
\frac{d}{dv}(e^{-\frac{m}{2kT}v^2}v^2)=0
$$<p>
</p>
$$
v_p=\sqrt{\frac{2kT}{m}}
$$<p>
Average speed $\overline{v}$: the average value of speed $v$
</p>
$$
\overline{v}=4\pi(\frac{m}{2\pi kT})^{3/2}\int_{0}^{\infty}ve^{-\frac{m}{2kT}v^2}v^2dv=\sqrt{\frac{8kT}{\pi m}}
$$<p>
Root-mean-square speed $v_s$: the square root of the average value of $v^2$
</p>
$$
v_s^2=\overline{v_2}=4\pi(\frac{m}{2\pi kT})^{3/2}\int_{0}^{\infty}v^2e^{-\frac{m}{2kT}v^2}v^2dv=\frac{3kT}{m}
$$<p>
</p>
$$
v_s=\sqrt{\frac{3kT}{m}}=\sqrt{\frac{3RT}{M}}
$$<p>
$M$: molar mass</p>
<h2 id="wall-collision-number-effusion">
<a class="header-anchor" href="#wall-collision-number-effusion"></a>
Wall Collision Number (Effusion)
</h2><blockquote>
<p>The number of molecules colliding with a unit area of the container wall per unit time is called the wall collision number.
The number of particles escaping per unit time through a unit area hole in the container wall is called effusion.
Clearly: Wall collision number = Effusion</p></blockquote>
<p>$dA$ is an infinitesimal area element on the container wall, with its normal direction along the $x$-axis. Let $d\varGamma dA dt$ represent the number of molecules that collide with area $dA$ within time $dt$, with velocities in the range $dv_xdv_ydv_z$.
</p>
$$
d\varGamma dA dt=fv_xdv_xdv_ydv_zdAdt
$$<p>
</p>
$$
d\varGamma=fv_xdv_xdv_ydv_z
$$<p>
Integrating over velocities,
</p>
$$
\begin{cases}
v_x,0\to \infty\\
v_y,-\infty \to +\infty\\
v_z,-\infty \to +\infty
\end{cases}
$$<p>
we obtain
</p>
$$
\varGamma=n\sqrt{\frac{kT}{2\pi m}}=
\frac{1}{4}n\overline{v}
$$<h2 id="equipartition-theorem-classical-statistics">
<a class="header-anchor" href="#equipartition-theorem-classical-statistics"></a>
Equipartition Theorem (Classical Statistics)
</h2><blockquote>
<p>For a <strong>classical system</strong> in equilibrium at temperature $T$, the <strong>average value</strong> of each independent quadratic term in the particle energy equals $\frac{1}{2}kT$.</p></blockquote>
<h2 id="monatomic-ideal-gas">
<a class="header-anchor" href="#monatomic-ideal-gas"></a>
Monatomic Ideal Gas
</h2>$$
\varepsilon=\frac{1}{2m}(p_x^2+p_y^2+p_z^2)
$$<p>
The above equation has three squared terms. Applying the equipartition theorem gives:
</p>
$$
\overline{\varepsilon}=\frac{3}{2}kT
$$<p>
Thus, the internal energy of a monatomic <strong>ideal gas</strong> is:
</p>
$$
U=\frac{3}{2}NkT
$$<p>
</p>
$$
C_V=\frac{3}{2}Nk
$$<p>
Using the thermodynamic relation $C_p-C_V=Nk$, the isobaric heat capacity is obtained as:
</p>
$$
C_p=\frac{5}{2}Nk
$$<h2 id="adiabatic-index">
<a class="header-anchor" href="#adiabatic-index"></a>
Adiabatic Index
</h2>$$
\gamma=\frac{C_p}{C_V}=\frac{5}{3}=1.667
$$<p>
[[#Ideal Gas Adiabatic Equation]]</p>
<h2 id="diatomic-molecular-gas">
<a class="header-anchor" href="#diatomic-molecular-gas"></a>
Diatomic Molecular Gas
</h2><blockquote>
<p>The energy of a diatomic molecule has five quadratic terms (momentum in three directions of the molecule, the motion between the two atoms can be reduced to a rotor, two degrees of freedom, i.e., two quadratic terms).</p></blockquote>
$$
\overline{\varepsilon}=\frac{5}{2}kT
$$<p>
</p>
$$
U=\frac{5}{2}NkT
$$<p>
</p>
$$
C_V=\frac{5}{2}Nk
$$<p>
</p>
$$
C_p=\frac{7}{2}Nk
$$<p>
</p>
$$
\gamma=\frac{C_p}{C_V}=\frac{7}{5}=1.4
$$<h2 id="solids">
<a class="header-anchor" href="#solids"></a>
Solids
</h2><blockquote>
<p>Atoms in a solid can undergo small vibrations around their equilibrium positions.
Assuming each atom&rsquo;s vibration is an independent simple harmonic motion,
the atomic model of a solid simplifies to a <strong>three-dimensional linear oscillator</strong>.</p></blockquote>
<p>The energy of an atom in <strong>one degree of freedom</strong> is:
</p>
$$
\varepsilon=\frac{1}{2m}p^2+\frac{1}{2}m\omega^2q^2
$$<p>
with two quadratic terms.<br>
The average energy per atom is:
</p>
$$
\overline{\varepsilon}=3kT
$$<p>
The internal energy of the solid is:
</p>
$$
U=3NkT
$$<p>
The heat capacity at constant volume is:
</p>
$$
C_V=3Nk
$$<p>
In experiments, $C_p$ is usually measured. Using the thermodynamic relation:
</p>
$$
C_p-C_V=\frac{TV\alpha^2}{\kappa T}
$$<p>
$C_V$ can be derived.<br>
At room temperature and high temperatures, $C_V$ matches predictions, but <strong>at low temperatures, the heat capacity drops rapidly with decreasing temperature—a phenomenon unexplained by classical theory.</strong><br>
[[#Principle of Unattainability of Absolute Zero]]</p>
<h2 id="metal">
<a class="header-anchor" href="#metal"></a>
Metal
</h2><p>There are free electrons in metals. If the equipartition theorem is applied to the electrons, the heat capacity of the free electrons would be of the same order of magnitude as the heat capacity of the ionic vibrations.
Experimental results show that above $3K$, the heat capacity of free electrons is negligible compared to the heat capacity of ionic vibrations.</p>
<h2 id="quantum-statistics-of-localizednearly-independent-particle-systems-satisfying-classical-limit-conditions">
<a class="header-anchor" href="#quantum-statistics-of-localizednearly-independent-particle-systems-satisfying-classical-limit-conditions"></a>
Quantum Statistics of Localized/Nearly Independent Particle Systems Satisfying Classical Limit Conditions
</h2><h2 id="diatomic-ideal-gas">
<a class="header-anchor" href="#diatomic-ideal-gas"></a>
Diatomic Ideal Gas
</h2><p>An ideal gas is a ==non-localized system==. Since it satisfies the [[#Classical Limit Condition]], it can be discussed using the Boltzmann distribution.</p>
<blockquote>
<p>Under certain approximations, the motion of diatomic molecules can be divided into <strong>translation $t$, vibration $v$, and rotation $r$</strong>.</p></blockquote>
$$
\varepsilon=\varepsilon^t+\varepsilon^v+\varepsilon^r
$$<p>
</p>
$$
\omega=\omega_t+\omega_v+\omega r
$$<p>
</p>
$$
Z_1=Z_1^t\cdot Z_1^v \cdot Z_1^r
$$<p>
</p>
$$
U=-N\frac{\partial}{\partial \beta}\ln Z_1=-N\frac{\partial}{\partial \beta}(\ln Z_1^t+\ln Z_1^v+\ln Z_1^r)=U^t+U^v+U^r
$$<p>
</p>
$$
C_V=C_V^t+C_V^v+C_V^r
$$<h2 id="translational-energy">
<a class="header-anchor" href="#translational-energy"></a>
Translational Energy
</h2>$$
\begin{cases}
Z_1^t=V(\frac{2\pi m}{h^2\beta})^{3/2}\\
U^t=\frac{3N}{2\beta}=\frac{3}{2}NkT\\
C_V^t=\frac{3}{2}Nk
\end{cases}
$$<p>
Consistent with the results obtained from the equipartition theorem of classical statistics.</p>
<h2 id="vibrational-energy-and-characteristic-temperature">
<a class="header-anchor" href="#vibrational-energy-and-characteristic-temperature"></a>
Vibrational Energy and Characteristic Temperature
</h2>$$
\begin{cases}
Z_1^v=\frac{e^{-\frac{\beta\hbar\omega}{2}}}{1-e^{-\beta\hbar\omega}}\\
U^v=\frac{N\hbar\omega}{2}+\frac{N\hbar\omega}{e^{\beta\hbar\omega}-1}\\
C_V^v=Nk(\frac{\hbar \omega}{kT})^2\cdot \frac{e^{\hbar \omega /kT}}{(e^{\hbar \omega/kT}-1)^2}
\end{cases}
$$<p>$U^v$:</p>
<ul>
<li>The first term is temperature-independent and represents the ==zero-point energy== of $N$ oscillators.</li>
<li>The second term is the ==thermal excitation energy== of $N$ oscillators at temperature $T$.</li>
</ul>
<p>Introducing the ==vibrational characteristic temperature== $\theta_v$, which satisfies:
</p>
$$
k\theta_v=\hbar\omega
$$<p>
Substituting into the above system of equations yields:
</p>
$$
\begin{cases}
U_v=\frac{Nk \theta_v}{e^{\frac{\theta_v}{T}}-1}\\
C_V^v=Nk(\frac{\theta_v}{T})^2\frac{e^{\frac{\theta_v}{T}}}{(e^{\frac{\theta_v}{T}}-1)^2}
\end{cases}
$$<p>
$\because$ The ==characteristic temperature of diatomic molecules== is on the order of $10^3K$,
$\therefore$ In the room temperature range, $T\ll \theta_v$. Within this range, the contribution of vibrational degrees of freedom to heat capacity is nearly zero.<br>
At room temperature, the energy level spacing $\hbar \omega$ of diatomic molecules is much larger than $kT$. Due to the discrete energy levels, oscillators must acquire energy $\hbar \omega$ to transition to an excited state.</p>
<ul>
<li>In the case of $T \ll \theta_v$, the probability of an oscillator acquiring thermal energy $\hbar \omega$ and transitioning to an excited state is extremely low. Thus, on average, <strong>almost all oscillators remain frozen in the ground state</strong>.<br>
When the gas temperature rises, they hardly absorb any energy (unable to transition to higher energy levels). This explains why ==vibrational degrees of freedom do not participate in energy equipartition at room temperature==.</li>
<li>In the case of $T \gg \theta_v$, $C_V^v \to Nk$ (can be proven using L&rsquo;Hôpital&rsquo;s rule).</li>
</ul>
<h2 id="rotational-energy">
<a class="header-anchor" href="#rotational-energy"></a>
Rotational Energy
</h2><p>Rotational energy levels
</p>
$$
\varepsilon^r=\frac{l(l+1)\hbar^2}{2I},l=0,1,2,\cdots
$$<p>
Degeneracy
</p>
$$
\omega^r=2l+1
$$<p>
Partition function
</p>
$$
Z_1^r=\sum_{i=0}^\infty(2l+1)e^{-\beta\frac{l(l+1)\hbar^2}{2I}}
$$<p>
Characteristic rotational temperature
</p>
$$
\theta_r=\frac{\hbar^2}{2Ik}<100K
$$<p>
</p>
$$
Z_1^r=\sum_{i=0}^{\infty}(2l+1)e^{-l(l+1)\frac{\theta_r}{T}}
$$<p>
==At room temperature== $\frac{\theta_r}{T}\ll 1$, integration yields
</p>
$$
Z_1^r=\frac{2I}{\beta \hbar^2}
$$<p>
From this we obtain
</p>
$$
\begin{cases}
U^r=NkT\\
C_V^r=Nk
\end{cases}
$$<p>Consistent with classical statistics.</p>
<h2 id="heteronuclear-diatomic-molecules">
<a class="header-anchor" href="#heteronuclear-diatomic-molecules"></a>
Heteronuclear Diatomic Molecules
</h2>$$
\begin{cases}
Z_1^t=V(\frac{2\pi m}{h_0^2\beta})^{3/2}\\
Z_1^v=\frac{2\pi}{h_0\beta \omega}\\
Z_1^r=\frac{8\pi^2I}{h_0^2\beta}
\end{cases}
$$<p>
</p>
$$
\begin{cases}
C_V^t=\frac{3}{2}Nk\\
C_V^v=Nk\\
C_V^r=Nk
\end{cases}
$$<h2 id="monatomic-ideal-gas-1">
<a class="header-anchor" href="#monatomic-ideal-gas-1"></a>
Monatomic Ideal Gas
</h2><h2 id="">
<a class="header-anchor" href="#"></a>

</h2><h2 id="entropy-1">
<a class="header-anchor" href="#entropy-1"></a>
Entropy
</h2><p>==Monatomic Ideal Gas==
</p>
$$
S=Nk(\ln Z_1-\beta\frac{\partial}{\partial \beta})-k \ln N!
$$<p>
Using the approximation $\ln N!=N(\ln N-1)$, it simplifies to
</p>
$$
S=\frac{3}{2}Nk \ln T+Nk \ln\frac{V}{N}+\frac{3}{2}Nk[\frac{5}{3}+\ln(\frac{2\pi mk}{h^2})]
$$<p>
The entropy in the above equation is an extensive quantity and represents absolute entropy.</p>
<h2 id="vapor-pressure-equation">
<a class="header-anchor" href="#vapor-pressure-equation"></a>
Vapor Pressure Equation
</h2><p>Sackur-Tetrode equation
</p>
$$
\ln p=-\frac{L}{RT}+\frac{5}{2}\ln T+\frac{5}{2}+\ln[k^5/2(\frac{2\pi m}{h^2})^3/2]
$$<h2 id="chemical-potential-1">
<a class="header-anchor" href="#chemical-potential-1"></a>
Chemical Potential
</h2>$$
\begin{align}
\mu &=(\frac{\partial F}{\partial N})_{T,V}\\
&=-kT \ln \frac{Z_1}{N}\\
&=kT \ln[\frac{N}{V}(\frac{h^2}{2\pi mkT})^3/2]
\end{align}
$$<p>
$\because$ For an ideal gas, $\frac{N}{V}(\frac{h^2}{2\pi mkT})^3/2\ll 1$<br>
$\therefore$ ==The chemical potential of an ideal gas is negative==.</p>
<h2 id="solids-1">
<a class="header-anchor" href="#solids-1"></a>
Solids
</h2><p>The thermal motion of atoms in a solid can be regarded as the vibration of $3N$ oscillators. <em>Einstein assumed that these $3N$ oscillators all have the same frequency.</em> Let $\omega$ denote the angular frequency of the oscillators, the energy levels of the oscillators are
</p>
$$
\varepsilon_n=\hbar \omega(n+\frac{1}{2}),n=0,1,2,\cdots
$$<p>
The partition function
</p>
$$
Z_1=\frac{e^{-\frac{\beta\hbar\omega}{2}}}{1-e^{-\beta\hbar\omega}}
$$<p>
Internal energy
</p>
$$
U=-3N \frac{\partial}{\partial \beta}\ln Z_1=3N \frac{\hbar \omega}{2}+3N\frac{\hbar \omega}{e^{\beta \hbar \omega}-1}
$$<p>
Heat capacity
</p>
$$
C_V=(\frac{\partial U}{\partial T})_V=3Nk(\frac{\hbar \omega}{kT})^2\frac{e^{\frac{\hbar \omega}{kT}}}{(e^{\frac{\hbar \omega}{kT}}-1)^2}
$$<p>
Introducing the ==Einstein characteristic temperature== $\theta_E=\frac{\hbar \omega}{k}$, the heat capacity can be rewritten as
</p>
$$
C_V=3Nk(\frac{\theta_E}{T})^2\frac{e^{\frac{\theta_E}{T}}}{(e^{\frac{\theta_E}{T}}-1)^2}
$$<ul>
<li>When $T \gg \theta_E$, the approximation $e^{\theta_E/T}-1\approx \theta_E/T$ can be made, yielding
$$
    C_V=3Nk
    $$
which is consistent with the result from the equipartition theorem.
At this point, the energy level spacing is much smaller than $kT$, and the quantization effect can be ignored.</li>
<li>When $T \ll \theta_E$, the approximation $e^{\frac{\theta_E}{T}}-1 \approx e^{\frac{\theta_E}{T}}$ holds,
$$
    C_V=3Nk(\frac{\theta_E}{T})^2e^{-\frac{\theta_E}{T}}
    $$
As $T \to 0$, $C_V \to 0$.
This proves the third law of thermodynamics[[#推论]].</li>
</ul>
<h2 id="bosefermi-systems">
<a class="header-anchor" href="#bosefermi-systems"></a>
Bose/Fermi Systems
</h2><p>[[#Bose Systems]], [[#Fermi Systems]].</p>
<h2 id="grand-partition-function-for-bosonic-systems">
<a class="header-anchor" href="#grand-partition-function-for-bosonic-systems"></a>
Grand Partition Function for Bosonic Systems
</h2>$$
\varXi=\prod_{l}\varXi_l=\prod_{l}(1-e^{-\alpha-\beta \varepsilon_l})^{-\omega_l}
$$<p>
</p>
$$
\ln \varXi=-\sum_i \omega_l \ln(1-e^{-\alpha-\beta \varepsilon_l})
$$<h2 id="average-particle-number">
<a class="header-anchor" href="#average-particle-number"></a>
Average Particle Number
</h2>$$
\overline{N}=\sum_l \frac{\omega_l}{e^{\alpha+\beta \varepsilon_l}-1}=-\frac{\partial}{\partial \alpha}\ln \varXi
$$<h2 id="internal-energy-1">
<a class="header-anchor" href="#internal-energy-1"></a>
Internal Energy
</h2>$$
U=\sum_l \frac{\varepsilon_l \omega_l}{e^{\alpha+\beta \varepsilon_l}-1}=-\frac{\partial}{\partial \beta}\ln \varXi
$$<h2 id="grand-partition-function-for-fermi-systems">
<a class="header-anchor" href="#grand-partition-function-for-fermi-systems"></a>
Grand Partition Function for Fermi Systems
</h2>$$
\varXi=\prod_{l}\varXi_l=\prod_{l}(1+e^{-\alpha-\beta \varepsilon_l})^{\omega_l}
$$<p>
</p>
$$
\ln \varXi=\sum_i \omega_l \ln(1+e^{-\alpha-\beta \varepsilon_l})
$$<h2 id="">
<a class="header-anchor" href="#"></a>

</h2><h2 id="average-particle-number-1">
<a class="header-anchor" href="#average-particle-number-1"></a>
Average Particle Number
</h2>$$
\overline{N}=\sum_l \frac{\omega_l}{e^{\alpha+\beta \varepsilon_l}+1}=-\frac{\partial}{\partial \alpha}\ln \varXi
$$<h2 id="internal-energy-2">
<a class="header-anchor" href="#internal-energy-2"></a>
Internal Energy
</h2>$$
U=\sum_l \frac{\varepsilon_l \omega_l}{e^{\alpha+\beta \varepsilon_l}+1}=-\frac{\partial}{\partial \beta}\ln \varXi
$$<h2 id="generalized-force">
<a class="header-anchor" href="#generalized-force"></a>
Generalized Force
</h2>$$
Y=-\frac{1}{\beta}\frac{\partial}{\partial y}\ln \varXi
$$<h2 id="equation-of-state-1">
<a class="header-anchor" href="#equation-of-state-1"></a>
Equation of State
</h2>$$
p=\frac{1}{\beta}\frac{\partial}{\partial V}\ln \varXi
$$<h2 id="entropy-2">
<a class="header-anchor" href="#entropy-2"></a>
Entropy
</h2>$$
\begin{align}
S &=k(\ln \varXi-\alpha \frac{\partial}{\partial \alpha}\ln \varXi-\beta \frac{\partial}{\partial \beta}\ln \varXi)\\
&=k(\ln \varXi+\alpha \overline{N}+\beta U)\\
&=k \ln \Omega
\end{align}
$$<h2 id="grand-potential-1">
<a class="header-anchor" href="#grand-potential-1"></a>
Grand Potential
</h2><p>[[#Grand Potential]]
</p>
$$
J=U-TS-\overline{N}\mu=-kT \ln \varXi
$$<h1 id="">
<a class="header-anchor" href="#"></a>

</h1><h2 id="lagrange-multiplier">
<a class="header-anchor" href="#lagrange-multiplier"></a>
Lagrange Multiplier
</h2>$$
\beta=\frac{1}{kT},\alpha=-\frac{\mu}{kT}
$$<hr>
<h2 id="tags">
<a class="header-anchor" href="#tags"></a>
title: Bose-Einstein Condensation
description:
keywords:
tags:
</h2><h2 id="system-properties">
<a class="header-anchor" href="#system-properties"></a>
System Properties
</h2><blockquote>
<p>Consider a system composed of $N$ identical, nearly independent bosons, with temperature $T$ and volume $V$. For clarity, assume the particles have zero spin.</p></blockquote>
<p>According to the Bose distribution, the number of particles in each energy level is
</p>
$$
a_l=\frac{\omega_l}{e^{\alpha+\beta \varepsilon_l}-1}=\frac{\omega_l}{e^{\frac{\varepsilon_l-\mu}{kT}}-1}
$$<p>
$\because$ The number of particles in an energy level cannot be negative,
$\therefore$ Let $\varepsilon_0$ denote the lowest energy level, $\varepsilon_0>\mu$.
If the lowest energy level is 0, then $\mu<0$.</p>
<h2 id="chemical-potential-2">
<a class="header-anchor" href="#chemical-potential-2"></a>
Chemical Potential
</h2><p>The chemical potential of a Bose system is less than 0. The chemical potential increases as the temperature decreases. When the temperature drops to a certain critical temperature $T_C$, $\mu \to 0$.
$T_C$ is determined by the following equation:
</p>
$$
\frac{2\pi}{h^3}(2m)^{3/2}\int_0^{\infty}\frac{\varepsilon^{1/2d \varepsilon}}{e^{\frac{\varepsilon}{kT_C}}-1}=n
$$<p>
</p>
$$
T_C=\frac{2\pi}{2.612^{2/3}}\frac{\hbar^2}{mk}n^{3/2}
$$<h2 id="condensation-phenomenon">
<a class="header-anchor" href="#condensation-phenomenon"></a>
Condensation Phenomenon
</h2><p>When $T \le T_C$, the ==particle number density== accumulated at the lowest energy level $\varepsilon=0$ is given by
</p>
$$
n_0(T)=n[1-(\frac{T}{T_C})^{3/2}]
$$<p>
At <strong>absolute zero</strong>, particles will occupy the lowest energy states as much as possible. For <strong>bosons</strong>, the number of particles that can occupy a single quantum state is unrestricted. Therefore, at absolute zero, all bosonic particles will be in the lowest energy level $\varepsilon=0$.</p>
<p>The above equation shows that:</p>
<blockquote>
<p>When $T < T_C$, a <strong>macroscopic number</strong> of particles condense into the lowest energy level. This phenomenon is called ==Bose-Einstein condensation==.</p></blockquote>
$$
U=0.770NkT(\frac{T}{T_C})^{3/2}
$$<p>
</p>
$$
C_V=(\frac{\partial U}{\partial T})_V=\frac{5}{2}\frac{U}{T}=1.925Nk(\frac{T}{T_C})^{3/2}
$$<p>
At $T=T_C$, $C_V$ reaches its maximum value of $1.925Nk$.<br>
When the <strong>temperature is sufficiently high</strong>,
</p>
$$
C_V=\frac{3}{2}Nk
$$<h2 id="critical-condition-for-bose-einstein-condensation-in-an-ideal-bose-gas">
<a class="header-anchor" href="#critical-condition-for-bose-einstein-condensation-in-an-ideal-bose-gas"></a>
Critical Condition for Bose-Einstein Condensation in an Ideal Bose Gas
</h2>$$
n(\frac{h}{\sqrt{2\pi mkT_C}})^3=n \lambda^3 \ge 2.612
$$<p>
$\lambda$: thermal de Broglie wavelength of atoms</p>
<h2 id="photon-gas-bose-gas">
<a class="header-anchor" href="#photon-gas-bose-gas"></a>
Photon Gas (Bose Gas)
</h2><blockquote>
<p>From the particle perspective, the radiation field inside an empty cavity can be regarded as a <strong>photon gas</strong>.
The radiation field inside the empty cavity can be decomposed into the superposition of infinitely many <strong>monochromatic plane waves</strong>.</p></blockquote>
<p>Based on the [[#de Broglie relations]], and the photon $\omega=ck$, we obtain the ==energy-momentum relation for photons==
</p>
$$
\varepsilon=cp
$$<ul>
<li>Photons are bosons with a spin quantum number of 1, and they obey Bose-Einstein statistics when in equilibrium.</li>
<li>Since the cavity walls continuously emit and absorb photons, the number of photons in the photon gas is not conserved. When deriving the Bose distribution, only the condition that $E$ is constant exists, and not the condition that $N$ is constant. Therefore, only one Lagrange multiplier $\beta$ should be introduced, with $\alpha=0$.</li>
</ul>
<h2 id="photon-gas-statistical-distribution">
<a class="header-anchor" href="#photon-gas-statistical-distribution"></a>
Photon Gas Statistical Distribution
</h2>$$
a_l=\frac{\omega_l}{e^{\beta \omega_l}-1}
$$<h2 id="thermodynamic-potential">
<a class="header-anchor" href="#thermodynamic-potential"></a>
Thermodynamic Potential
</h2><p>From
</p>
$$
\alpha=-\frac{\mu}{kT}=0
$$<p>
we obtain the thermodynamic potential of the photon gas as $\mu=0$.</p>
<h2 id="number-of-quantum-states">
<a class="header-anchor" href="#number-of-quantum-states"></a>
Number of Quantum States
</h2><p>The spin quantum number of a photon is 1, and its spin projection along the momentum direction can take two possible values, $\pm \hbar$, corresponding to left and right circular polarization. Considering that the photon spin has 2 projections, as shown in the [[#Energy Representation]] section of [[#Number of Quantum States for a Three-Dimensional Free Particle]],</p>
<blockquote>
<p>Within a cavity of volume $V$, in the momentum range from $p$ to $p+dp$,</p></blockquote>
<p>the number of quantum states for photons is
</p>
$$
\Omega=\frac{8\pi V}{h^3}p^2dp
$$<blockquote>
<p>Within a cavity of volume $V$, in the angular frequency range from $\omega$ to $\omega+d \omega$,</p></blockquote>
<p>the number of quantum states for photons is
</p>
$$
\Omega=\frac{V}{\pi^2c^3}\omega^2d \omega
$$<h2 id="energy-distribution-function">
<a class="header-anchor" href="#energy-distribution-function"></a>
Energy Distribution Function
</h2><blockquote>
<p>In a cavity of volume $V$, within the frequency range from $\omega$ to $\omega+d \omega$,</p></blockquote>
<p>The average number of photons
</p>
$$
\overline{N}=\frac{V}{\pi^2c^3}\frac{\omega^2d \omega}{e^{\hbar \omega/kT}-1}
$$<p>
The energy of the radiation field
</p>
$$
U(\omega,T)d \omega=\overline{N}\hbar \omega=\frac{V}{\pi^2c^3}\frac{\hbar \omega^3}{e^{\hbar \omega/kT}-1}d \omega
$$<h2 id="">
<a class="header-anchor" href="#"></a>

</h2><h2 id="rayleigh-jeans-law">
<a class="header-anchor" href="#rayleigh-jeans-law"></a>
Rayleigh-Jeans Law
</h2><p>In the low-frequency range where $\frac{\hbar \omega}{kT}\ll 1$, $e^{\frac{\hbar \omega}{kT}}\approx 1+\frac{\hbar \omega}{kT}$, the above equation can be approximated as
</p>
$$
U(\omega,T)d \omega=\frac{V}{\pi^2c^3}\omega^2kTd \omega
$$<p>
This equation is known as the ==Rayleigh-Jeans Law==, which <strong>fits well at low frequencies</strong> but leads to the ultraviolet catastrophe at high frequencies.</p>
<h2 id="wiens-law">
<a class="header-anchor" href="#wiens-law"></a>
Wien&rsquo;s Law
</h2><p>In the high-frequency range where $\frac{\hbar \omega}{kT}\gg 1$, $e^{\frac{\hbar \omega}{kT}}-1\approx e^{\frac{\hbar \omega}{kT}}$, the above equation can be approximated as
</p>
$$
U(\omega,T)d \omega=\frac{V}{\pi^2c^3}\hbar \omega^3e^{-\frac{\hbar \omega}{kT}}d \omega
$$<p>
This formula matches Wien&rsquo;s Law, providing good agreement at high frequencies but poor agreement at low frequencies.</p>
<blockquote>
<p>Inside a cavity of volume $V$</p></blockquote>
<p>The internal energy of equilibrium radiation is
</p>
$$
U=\frac{\pi^2k^4}{15c^3\hbar^3}VT^4
$$<h2 id="grand-partition-function">
<a class="header-anchor" href="#grand-partition-function"></a>
Grand Partition Function
</h2>$$
\ln \varXi=\frac{pi^2V}{45c^3}\frac{1}{(\beta \hbar)^3}
$$<h2 id="photon-gas-internal-energy">
<a class="header-anchor" href="#photon-gas-internal-energy"></a>
Photon Gas Internal Energy
</h2>$$
U=-\frac{\partial}{\partial \beta}\ln \varXi=\frac{\pi^2k^4V}{15c^3\hbar^3}T^4
$$<p>
Consistent with [[#Internal Energy Distribution Function]]</p>
<h2 id="pressure">
<a class="header-anchor" href="#pressure"></a>
Pressure
</h2>$$
p=-\frac{1}{\beta}\frac{\partial}{\partial V}\ln \varXi=\frac{\pi^2k^4}{45c^3\hbar^3}T^4
$$<p>
Comparing the above two equations gives
</p>
$$
p=\frac{1}{3}\frac{U}{V}
$$<h2 id="entropy-3">
<a class="header-anchor" href="#entropy-3"></a>
Entropy
</h2>$$
S=k(\ln \varXi+\beta U)=\frac{4}{45}\frac{\pi^2k^4}{c^3\hbar^3}T^3V
$$<p>
When $T \to 0$, $S \to 0$, consistent with [[#Third Law of Thermodynamics]]</p>
<h2 id="radiation-flux-density">
<a class="header-anchor" href="#radiation-flux-density"></a>
Radiation Flux Density
</h2><p>The formula for [[#Radiation Flux Density]] derived from [[#Radiation]] is
</p>
$$
J_u=\frac{c}{4}\frac{U}{V}=\frac{1}{4}cu
$$<p>
Based on the concept of [[#Wall Collision Rate (Effusion)]], the radiation flux density of a photon gas is obtained as
</p>
$$
J_u=\frac{\pi^2k^4}{60c^2\hbar^3}T^4
$$<h2 id="free-electron-gas-in-metals-fermi-gas">
<a class="header-anchor" href="#free-electron-gas-in-metals-fermi-gas"></a>
Free Electron Gas in Metals (Fermi Gas)
</h2><blockquote>
<p>The free electrons in metals form a highly degenerate Fermi gas.</p></blockquote>
<h2 id="average-electron-number">
<a class="header-anchor" href="#average-electron-number"></a>
Average Electron Number
</h2><p>According to the Fermi distribution, at temperature $T$, the average number of electrons occupying a quantum state with energy $\varepsilon$ is:
</p>
$$
f=\frac{1}{e^{\frac{\varepsilon-\mu}{kT}}+1}
$$<p>
The electron spin has 2 possible projections along its momentum direction. Based on the [[#Energy Representation]] in [[#Three-Dimensional Free Particle Quantum State Number]],</p>
<blockquote>
<p>Within volume $V$, the number of electron quantum states in the energy range from $\varepsilon$ to $\varepsilon+d \varepsilon$ is:</p></blockquote>
$$
D(\varepsilon)d\varepsilon=\frac{4\pi V}{h^3}(2m)^{3/2}\varepsilon^{1/2}d\varepsilon
$$<p>
Thus, the average number of electrons in this range is:
</p>
$$
dN=f \cdot D(\varepsilon)d\varepsilon=\frac{4\pi V}{h^3}(2m)^{3/2}\frac{\varepsilon^{1/2}d\varepsilon}{e^{\frac{\varepsilon-\mu}{kT}}+1}
$$<h2 id="total-number-of-electrons">
<a class="header-anchor" href="#total-number-of-electrons"></a>
Total Number of Electrons
</h2><p>Integrating over $d \varepsilon$ gives
</p>
$$
\frac{4\pi V}{h^3}(2m)^{3/2}\int_0^{\infty}\frac{\varepsilon^{1/2}d\varepsilon}{e^{\frac{\varepsilon-\mu}{kT}}+1}=N
$$<p>
Given the number of electrons $N$, temperature $T$, and volume $V$, the chemical potential $\mu$ can be determined from the above equation.</p>
<h2 id="system-properties-at">
<a class="header-anchor" href="#system-properties-at"></a>
System Properties at $T=0$
</h2><h2 id="average-electron-number-per-quantum-state">
<a class="header-anchor" href="#average-electron-number-per-quantum-state"></a>
Average Electron Number per Quantum State
</h2>$$
\begin{cases}
f=1,\varepsilon<\mu(0)\\
f=0,\varepsilon>\mu(0)
\end{cases}
$$<h2 id="fermi-level">
<a class="header-anchor" href="#fermi-level"></a>
Fermi Level
</h2><blockquote>
<p>The chemical potential at zero temperature is also known as the Fermi level, $\mu(0)$, which is the chemical potential when $T=0$.</p></blockquote>
<p>From
</p>
$$
\frac{4\pi V}{h^3}(2m)^{3/2}\int_0^{\mu(0)}\varepsilon^{1/2}d \varepsilon=N
$$<p>
we obtain
</p>
$$
\mu(0)=\frac{\hbar^2}{2m}(3\pi^2\frac{N}{V})^{2/3}
$$<h2 id="fermi-momentum">
<a class="header-anchor" href="#fermi-momentum"></a>
Fermi Momentum
</h2><p>Let
</p>
$$
\mu(0)=\frac{p_F^2}{2m}
$$<p>
we obtain
</p>
$$
p_F=(3\pi^2n)^{1/3}\hbar
$$<p>
This momentum is called ==Fermi momentum==.</p>
<h2 id="fermi-velocity">
<a class="header-anchor" href="#fermi-velocity"></a>
Fermi Velocity
</h2>$$
v_F=\frac{p_F}{m}
$$<p>
This velocity is called the ==Fermi velocity==.</p>
<h2 id="fermi-temperature">
<a class="header-anchor" href="#fermi-temperature"></a>
Fermi Temperature
</h2>$$
kT_F=\mu(0)
$$<p>
</p>
$$
T_F=\frac{\mu(0)}{k}
$$<p>
This temperature is called the ==Fermi temperature==.</p>
<h2 id="energy-of-electron-gas">
<a class="header-anchor" href="#energy-of-electron-gas"></a>
Energy of Electron Gas
</h2>$$
U(0)=\frac{4\pi V}{h^3}(2m)^{3/2}\int_0^{\mu(0)}\varepsilon^{3/2}d \varepsilon=\frac{3N}{5}\mu(0)
$$<h2 id="">
<a class="header-anchor" href="#"></a>

</h2><h2 id="electron-average-energy">
<a class="header-anchor" href="#electron-average-energy"></a>
Electron Average Energy
</h2>$$
u(0)=\frac{U(0)}{N}=\frac{3}{5}\mu(0)
$$<h2 id="">
<a class="header-anchor" href="#"></a>

</h2><h2 id="electron-gas-pressure">
<a class="header-anchor" href="#electron-gas-pressure"></a>
Electron Gas Pressure
</h2>$$
p(0)=\frac{2}{3}\frac{U(0)}{V}=\frac{2}{5}n \mu(0)
$$<h2 id="comparison-of-bose-and-fermi-gases-at">
<a class="header-anchor" href="#comparison-of-bose-and-fermi-gases-at"></a>
Comparison of Bose and Fermi Gases at $T=0$
</h2><p>In stark contrast to an ideal Bose gas, where all particles occupy the zero-energy, zero-momentum ground state with zero pressure at absolute zero temperature, a Fermi gas possesses extremely high average energy and momentum, generating substantial pressure at absolute zero.</p>

        
        <hr><p>Published on 2024-06-06 at <a href='https://guzhengsvt.cn/'>孤筝の温暖小家</a>, last modified on 2024-06-06</p><p>Unless otherwise stated, all posts on this blog are licensed under the BY-NC-SA license. Please credit the source when reposting!</p>]]>
      </description>
      
        <category>Physics</category>
      
    </item>
    
  </channel>
</rss>
